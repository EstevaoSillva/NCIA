{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Descritores Locais: SIFT, ORB e Matching\n",
                "\n",
                "**Nota:** Este notebook foca na descrição local de imagens, permitindo o reconhecimento de objetos sob oclusão, rotação e mudanças de escala.\n",
                "\n",
                "## 1) O Pipeline de Descritores Locais\n",
                "\n",
                "O processo padrão para trabalhar com features locais envolve:\n",
                "1.  **Detecção:** Encontrar pontos de interesse (keypoints) distintos.\n",
                "2.  **Descrição:** Extrair um vetor numérico (fingerprint) da vizinhança de cada ponto.\n",
                "3.  **Matching:** Comparar vetores entre imagens para achar correspondências.\n",
                "4.  **Transformação:** Usar os matches para geometria (homografia) ou estatística (BoVW).\n",
                "\n",
                "> **Conceito:** Após a extração, a imagem original é frequentemente descartada, e trabalhamos apenas com a nuvem de vetores descritores."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2) SIFT (Scale-Invariant Feature Transform)\n",
                "\n",
                "O SIFT (Lowe, 2004) é o algoritmo clássico que resolve a invariância a escala e rotação.\n",
                "\n",
                "### Funcionamento Resumido:\n",
                "- **Detecção (Scale Space):** Usa Diferença de Gaussianas (DoG) para achar pontos estáveis em várias escalas.\n",
                "- **Descrição (HOG Local):** Divide a vizinhança 16x16 em 4x4 sub-blocos. Em cada sub-bloco, calcula um histograma de 8 orientações.\n",
                "- **Resultado:** Um vetor de $4 \\times 4 \\times 8 = 128$ dimensões.\n",
                "\n",
                "O SIFT é robusto, mas computacionalmente intenso."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from skimage import data\n",
                "\n",
                "# Setup: Imagem original e uma versão transformada (Simulando outra vista)\n",
                "img1_cl = data.camera()\n",
                "rows, cols = img1_cl.shape\n",
                "# Rotação de 30 graus e escala de 1.1x\n",
                "M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1.1)\n",
                "img2_cl = cv2.warpAffine(img1_cl, M, (cols, rows))\n",
                "\n",
                "# 1. Instanciar SIFT (com fallback para ORB)\n",
                "try:\n",
                "    detector = cv2.SIFT_create()\n",
                "    norm = cv2.NORM_L2\n",
                "    is_orb = False\n",
                "except AttributeError:\n",
                "    print(\"SIFT indisponível, usando ORB.\")\n",
                "    detector = cv2.ORB_create()\n",
                "    norm = cv2.NORM_HAMMING\n",
                "    is_orb = True\n",
                "\n",
                "# 2. Detectar e Descrever\n",
                "kp1, des1 = detector.detectAndCompute(img1_cl, None)\n",
                "kp2, des2 = detector.detectAndCompute(img2_cl, None)\n",
                "\n",
                "# Visualizar Keypoints\n",
                "out_img = cv2.drawKeypoints(img1_cl, kp1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
                "plt.figure(figsize=(6,6))\n",
                "plt.imshow(out_img)\n",
                "plt.title(f\"Detecção ({'ORB' if is_orb else 'SIFT'}): {len(kp1)} pontos\")\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Matching com Ratio Test\n",
                "Para conectar os pontos, usamos um Matcher. O **Ratio Test de Lowe** descarta matches ambíguos.\n",
                "Aceitamos o match se a distância do vizinho mais próximo for significativamente menor que a do segundo mais próximo ($d_1 < 0.75 \\cdot d_2$)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bf = cv2.BFMatcher(norm)\n",
                "matches = bf.knnMatch(des1, des2, k=2)\n",
                "\n",
                "good = []\n",
                "for m, n in matches:\n",
                "    # Ratio test\n",
                "    thresh = 0.75\n",
                "    # Ajuste para ORB (hammings distances são inteiros, 0.75 as vezes é agressivo demais, mas padrão é ok)\n",
                "    if m.distance < thresh * n.distance:\n",
                "        good.append(m)\n",
                "\n",
                "img_matches = cv2.drawMatches(img1_cl, kp1, img2_cl, kp2, good, None, flags=2)\n",
                "\n",
                "plt.figure(figsize=(12,6))\n",
                "plt.imshow(img_matches)\n",
                "plt.title(f\"Matches Filtrados: {len(good)}\")\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3) Matching Geométrico (RANSAC)\n",
                "\n",
                "O RANSAC (Random Sample Consensus) limpa os outliers restantes impondo uma restrição geométrica (Homografia). Ele encontra a matriz de transformação que alinha a maioria dos pontos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if len(good) >= 4:\n",
                "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
                "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
                "\n",
                "    # Encontrar Homografia com RANSAC\n",
                "    M_hom, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
                "    matchesMask = mask.ravel().tolist()\n",
                "\n",
                "    # Visualizar apenas os Inliers (Verdes)\n",
                "    draw_params = dict(matchColor = (0,255,0), \n",
                "                       singlePointColor = None,\n",
                "                       matchesMask = matchesMask, \n",
                "                       flags = 2)\n",
                "\n",
                "    img3 = cv2.drawMatches(img1_cl, kp1, img2_cl, kp2, good, None, **draw_params)\n",
                "\n",
                "    plt.figure(figsize=(12,6))\n",
                "    plt.imshow(img3)\n",
                "    plt.title(f\"RANSAC Inliers ({sum(matchesMask)}/{len(good)})\")\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Matches insuficientes para RANSAC.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4) Outros Descritores: SURF, FAST e ORB\n",
                "\n",
                "- **SURF:** Versão acelerada do SIFT usando Box Filters e Imagens Integrais. (frequentemente patenteado).\n",
                "- **FAST:** Detector de cantos de alta velocidade (Decision Tree em círculo de pixels). Não descreve o ponto.\n",
                "- **ORB:** Combinação de FAST (detector) + BRIEF (descritor binário). É a escolha padrão para aplicações em tempo real (SLAM, Mobile)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comparação Rápida com ORB (se já não estiver usando)\n",
                "orb = cv2.ORB_create()\n",
                "kp_o, des_o = orb.detectAndCompute(img1_cl, None)\n",
                "\n",
                "# ORB gera muito mais pontos por padrão (nfeatures=500)\n",
                "img_orb_vis = cv2.drawKeypoints(img1_cl, kp_o, None, color=(255,0,0))\n",
                "plt.figure(figsize=(6,6))\n",
                "plt.imshow(img_orb_vis)\n",
                "plt.title(f\"ORB Keypoints: {len(kp_o)}\")\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5) Representação Global: Bag of Visual Words (BoVW)\n",
                "\n",
                "Para classificar cenas inteiras usando SIFT, usamos BoVW:\n",
                "1. Extraímos SIFT de muitas imagens.\n",
                "2. Clusterizamos (K-Means) para achar \"Palavras Visuais\" (centróides).\n",
                "3. Convertemos cada nova imagem em um histograma de palavras."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.cluster import KMeans\n",
                "\n",
                "# Demo BoVW Simplificado\n",
                "# Dataset: 4 Imagens\n",
                "imgs_bovw = [data.chelsea(), data.astronaut(), data.coffee(), data.rocket()]\n",
                "gray_imgs = [cv2.cvtColor(i, cv2.COLOR_RGB2GRAY) for i in imgs_bovw]\n",
                "labels = ['Gato', 'Astronauta', 'Café', 'Foguete']\n",
                "\n",
                "# 1. Extrair Features\n",
                "all_des = []\n",
                "des_list = []\n",
                "for g in gray_imgs:\n",
                "    kp, des = detector.detectAndCompute(g, None)\n",
                "    if des is None: des = np.array([])\n",
                "    all_des.append(des)\n",
                "    des_list.append(des)\n",
                "\n",
                "# Empilhar (supondo que achamos features em todas)\n",
                "if all(d.shape[0] > 0 for d in all_des):\n",
                "    stack = np.vstack(all_des)\n",
                "\n",
                "    # 2. Criar Vocabulário (K=5 palavras para demo visual)\n",
                "    kmeans = KMeans(n_clusters=5, random_state=0, n_init=10)\n",
                "    kmeans.fit(stack)\n",
                "\n",
                "    # 3. Gerar Histogramas\n",
                "    plt.figure(figsize=(15,3))\n",
                "    for i, (des, label) in enumerate(zip(des_list, labels)):\n",
                "        words = kmeans.predict(des)\n",
                "        hist, bin_edges = np.histogram(words, bins=5, range=(0,5))\n",
                "        \n",
                "        # Normalizar\n",
                "        hist = hist / hist.sum()\n",
                "        \n",
                "        plt.subplot(1, 4, i+1)\n",
                "        plt.bar(range(5), hist, color='purple', alpha=0.7)\n",
                "        plt.title(label)\n",
                "        plt.ylim(0, 1.0)\n",
                "        plt.xlabel(\"Visual Word Index\")\n",
                "    \n",
                "    plt.suptitle(\"Assinaturas BoVW\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6) Exercícios\n",
                "\n",
                "1.  **Robustez:** Teste o matching SIFT/ORB com uma imagem borrada (`cv2.GaussianBlur`). O número de inliers cai drasticamente?\n",
                "2.  **RANSAC:** Modifique o `ransacReprojThreshold` (o valor 5.0 no código). Se aumentar para 20.0, o que acontece com a precisão do alinhamento?\n",
                "3.  **BoVW:** Por que usar um vocabulário pequeno (ex: 5 palavras) é ruim para discriminar objetos complexos? Pense em termos de \"poder de representação\"."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
