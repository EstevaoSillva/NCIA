{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKEL771xMw2a"
      },
      "source": [
        "![NCIA](NCIA_Images\\start.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItHZYTlmMw2b"
      },
      "source": [
        "# Building Neural Networks with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G7hR0ZUMw2c"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsxvtjeHMw2c"
      },
      "source": [
        "Este projeto requer Python 3.10 ou superior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0ApDnOxMw2c",
        "outputId": "b49d8fa6-c0f2-4246-9ff9-109bb7c569d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\antonio.fontenele\\Documents\\NCIA\\Material_Aulas\\Aula 32\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pandas matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSH6GiwPMw2d"
      },
      "source": [
        "<div align=\"center\" style=\"margin-top:20px; margin-bottom:20px;\">\n",
        "  \n",
        "![pt](Aula_Imagens/pytorch.png)\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPftgDAWMw2d"
      },
      "source": [
        "   \n",
        "   Isso demora 9 minutos =/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v3qtx9HMw2d",
        "outputId": "d4948c98-eb88-47a7-a210-ac68bf4d5003"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\antonio.fontenele\\Documents\\NCIA\\Material_Aulas\\Aula 32\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch>=2.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDF0JNgHMw2e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v0vJMkeMw2e"
      },
      "source": [
        "Também requer Scikit-Learn ≥ 1.6.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRpUlw8bMw2f"
      },
      "outputs": [],
      "source": [
        "from packaging.version import Version\n",
        "import sklearn\n",
        "assert Version(sklearn.__version__) >= Version(\"1.6.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHXQTkRKMw2f"
      },
      "source": [
        "E é claro que precisamos do PyTorch, especificamente do PyTorch ≥ 2.8.0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rydhV_w5Mw2f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "assert Version(torch.__version__) >= Version(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmDyQUYcMw2f"
      },
      "source": [
        "Como fizemos nos capítulos anteriores, vamos definir os tamanhos de fonte padrão para deixar as figuras mais bonitas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUtQj1mzMw2f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wBXxsVhMw2f"
      },
      "source": [
        "## Sobre o Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd_QD6HXMw2g"
      },
      "source": [
        "PyTorch é uma biblioteca open source de deep learning (originada do Torch/Lua) mantida pelo laboratório FAIR (Meta AI). Em Python, oferece **tensores**, **autodiferenciação (autograd)**, **aceleração por GPU/TPU** e um ecossistema de **camadas, perdas e otimizadores prontos**, tornando o desenvolvimento de redes neurais ágil e produtivo. Conceitualmente, lembra o NumPy, mas com suporte nativo a **cálculo em hardware acelerado** e **gradientes automáticos**.\n",
        "\n",
        "\"PôfêSô, por que Pt? eu gostava do TF!\" Em 2016, o **TensorFlow** dominava o cenário por desempenho e escalabilidade, porém seu modelo de programação era mais **estático e complexo**. O PyTorch foi criado com uma proposta **mais “pythônica” e dinâmica**, usando **grafos computacionais dinâmicos (define-by-run)**, o que facilita a **depuração**, a **exploração interativa** e a **pesquisa**.\n",
        "Além do design limpo e documentação robusta, a comunidade open source cresceu rapidamente; em 2022, a governança migrou para a **PyTorch Foundation** (Linux Foundation), consolidando o ecossistema. O resultado prático foi a **adoção massiva na academia** e, por consequência, **migração gradual da indústria**.\n",
        "\n",
        "## O que você aprenderá neste capítulo\n",
        "\n",
        "* **Fundamentos**: como trabalhar com **tensores** e **autograd** no PyTorch.\n",
        "* **Primeiros passos de modelagem**: construir e treinar um **modelo de regressão linear** para entender o pipeline básico.\n",
        "* **Evolução para redes profundas**: ampliar para **redes multicamadas (MLP)**:\n",
        "\n",
        "  * **Regressão** com redes neurais.\n",
        "  * **Classificação** com redes neurais.\n",
        "* **Arquiteturas personalizadas**: criar modelos com **múltiplas entradas** ou **múltiplas saídas**.\n",
        "* **Ajuste de hiperparâmetros**: usar **Optuna** para **tunar** modelos automaticamente.\n",
        "* **Otimização e exportação**: técnicas para **otimizar desempenho** e **salvar/exportar** modelos para uso em produção.\n",
        "\n",
        "> **Resumo da ideia central**: PyTorch equilibra **simplicidade**, **flexibilidade** e **alto desempenho** graças aos **grafos dinâmicos** e ao **ecossistema maduro**. Este capítulo guia você do **básico (tensores/autograd)** à **produção (tuning, otimização e exportação)** passando por exemplos práticos de **regressão** e **classificação**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWvkyK01Mw2g"
      },
      "source": [
        "# 1. Fundamentos do PyTorch\n",
        "\n",
        "O **tensor** é a estrutura de dados central do PyTorch: um **array multidimensional** com **forma** e **tipo de dado**, usado para computação numérica. Ele é semelhante a um array do **NumPy**, mas tem duas vantagens fundamentais: pode **residir em GPU** (ou outros aceleradores) e **suporta auto-diferenciação**. A partir deste ponto, **todos os modelos** trabalharão **recebendo e produzindo tensores**, de modo análogo a como modelos do Scikit-Learn usam arrays NumPy. O próximo passo é **criar e manipular tensores**.\n",
        "\n",
        "## 1.1 PyTorch Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gviZtnerMw2g"
      },
      "source": [
        "Você pode criar um tensor PyTorch da mesma forma que criaria um array NumPy. Por exemplo, vamos criar um array 2 × 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzdWT-ydMw2g",
        "outputId": "92b1f5fb-eb9f-4f37-97e7-35207ec3739b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqGrDie4Mw2g"
      },
      "source": [
        "Assim como um array do NumPy, um **tensor** pode conter **floats**, **inteiros**, **booleanos** ou **números complexos** — **apenas um tipo por tensor**. Se você o inicializa com valores de tipos mistos, o PyTorch escolhe o **mais geral** segundo a hierarquia: **complexo > float > inteiro > bool**. Também é possível **definir o tipo explicitamente** na criação (por exemplo, `dtype=torch.float16` para floats de 16 bits). **Tensores de strings ou objetos não são suportados**.\n",
        "\n",
        "> Você pode **inspecionar a forma (shape) e o tipo (dtype)** de um tensor diretamente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tZM0W49Mw2g",
        "outputId": "73bf250f-7b1a-4aaf-d283-63d0625d1459"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1s9DODUMw2h",
        "outputId": "14b062fe-c3c3-40b0-b345-cb19359c759c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf2YwhSoMw2h"
      },
      "source": [
        "A indexação funciona exatamente como para matrizes NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq4Dn_JyMw2h",
        "outputId": "dd36a8bd-e539-4688-8675-c854f75e260d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF3ZVDg7Mw2h",
        "outputId": "4dd0ffdc-eb4a-4977-a9f8-bb8f00368b1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4., 3.])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujDEsJX4Mw2h"
      },
      "source": [
        "Você pode aplicar **diversas operações numéricas** diretamente em tensores, com uma API **muito semelhante à do NumPy**: `torch.abs()`, `torch.cos()`, `torch.exp()`, `torch.max()`, `torch.mean()`, `torch.sqrt()`, entre outras.\n",
        "Quase todas também existem como **métodos do próprio tensor**, permitindo escrever `X.exp()` em vez de `torch.exp(X)`. O próximo trecho demonstra algumas dessas operações na prática."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWdSZXWjMw2h",
        "outputId": "b2d33305-a647-4595-ed3c-495f7f7cc918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[20., 50., 80.],\n",
              "        [30., 40., 70.]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "10 * (X + 1.0)  # item-wise addition and multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM4STRE-Mw2i",
        "outputId": "2132302b-2c67-4ad3-f092-a60083e331f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   2.7183,   54.5981, 1096.6332],\n",
              "        [   7.3891,   20.0855,  403.4288]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.exp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ0hqSwRMw2i",
        "outputId": "e1822065-c6af-4154-d51d-6ec87c91bc9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.8333)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JezKyEuMw2i",
        "outputId": "4368f409-6708-4c4e-9f0c-5319f1236a76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([2., 4., 7.]),\n",
              "indices=tensor([1, 0, 0]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.max(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dtu6NNCBMw2i",
        "outputId": "7d0a4e4a-5f7e-48ee-fffb-58036e463d88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[66., 56.],\n",
              "        [56., 49.]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X @ X.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oANY898Mw2i"
      },
      "source": [
        "Você também pode converter um tensor em uma matriz NumPy usando o método numpy() e criar um tensor a partir de uma matriz NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDi_1dCyMw2i",
        "outputId": "1698bbb9-16c0-4dee-a232-e165f932d46b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 4., 7.],\n",
              "       [2., 3., 6.]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h_bK1qSMw2i",
        "outputId": "36eeb627-aa23-420c-8b5a-f346341191f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EisOfMW4Mw2j"
      },
      "source": [
        "No PyTorch, o **padrão de floats é 32 bits (float32)**, enquanto no NumPy é **64 bits (float64)**. Em deep learning, **float32 costuma ser preferível**: consome **metade da RAM**, **acelera os cálculos** e a rede **não precisa** da precisão extra de 64 bits.\n",
        "Ao converter um array NumPy com `torch.tensor()`, **indique** `dtype=torch.float32`. Como alternativa, `torch.FloatTensor()` **já converte** automaticamente para **32 bits**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nTrxt9WMw2j",
        "outputId": "969de679-2271-4b5a-c1c4-99296194fe95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXQBKwNxMw2j",
        "outputId": "94b3155f-6cf4-4a46-cc4d-f967d8644e14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 4., 7.],\n",
              "        [2., 3., 6.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.FloatTensor(np.array([[1., 4., 7.], [2., 3., 6]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYm0ri6nMw2j",
        "outputId": "044c0546-6084-4cb1-c5b7-bd9670dc8d2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1., 88.,  7.],\n",
              "        [ 2.,  3.,  6.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code: demonstrate torch.from_numpy()\n",
        "X2_np = np.array([[1., 4., 7.], [2., 3., 6]])\n",
        "X2 = torch.from_numpy(X2_np)  # X2_np and X2 share the same data in memory\n",
        "X2_np[0, 1] = 88\n",
        "X2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE6RtxxxMw22"
      },
      "source": [
        "Você também pode modificar um tensor no local usando indexação e fatiamento, como com uma matriz NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIRMYjELMw22",
        "outputId": "7c51c4e4-e5c7-46b7-82b3-c767edeb81d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  1., -99.,   7.],\n",
              "        [  2., -99.,   6.]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[:, 1] = -99\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbPAKhNCMw22"
      },
      "source": [
        "A API do PyTorch oferece diversas operações **in-place** (terminadas com `_`), como `abs_()`, `sqrt_()` e `zero_()`, que **modificam o próprio tensor**. Elas podem **economizar memória** e **aumentar a velocidade** em alguns casos.\n",
        "Exemplo: `relu_()` aplica a **ReLU** diretamente, **substituindo valores negativos por 0** no mesmo tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7zaXjetMw22",
        "outputId": "d26ab30a-b56d-4507-db15-9a96cff6bcde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 7.],\n",
              "        [2., 0., 6.]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.relu_()\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIMCuNEeMw23"
      },
      "source": [
        "Os tensores do PyTorch realmente se assemelham a matrizes NumPy. Na verdade, eles têm mais de 200 funções comuns!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXdJ476OMw23",
        "outputId": "dfc2dd45-b026-4d78-fce2-61149f8ba3b0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'__getattr__, abs, absolute, acos, acosh, add, all, allclose, amax, amin, angle, any, arange, arccos, arccosh, arcsin, arcsinh, arctan, arctan2, arctanh, argmax, argmin, argsort, argwhere, asarray, asin, asinh, atan, atan2, atanh, atleast_1d, atleast_2d, atleast_3d, bincount, bitwise_and, bitwise_left_shift, bitwise_not, bitwise_or, bitwise_right_shift, bitwise_xor, broadcast_shapes, broadcast_to, can_cast, ceil, clip, column_stack, concat, concatenate, conj, copysign, corrcoef, cos, cosh, count_nonzero, cov, cross, cumprod, cumsum, deg2rad, diag, diagflat, diagonal, diff, divide, dot, dsplit, dstack, dtype, einsum, empty, empty_like, equal, exp, exp2, expm1, eye, finfo, fix, flip, fliplr, flipud, float_power, floor, floor_divide, fmax, fmin, fmod, frexp, from_dlpack, frombuffer, full, full_like, gcd, gradient, greater, greater_equal, heaviside, histogram, histogramdd, hsplit, hstack, hypot, i0, iinfo, imag, inner, isclose, isfinite, isin, isinf, isnan, isneginf, isposinf, isreal, kron, lcm, ldexp, less, less_equal, linspace, load, log, log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not, logical_or, logical_xor, logspace, matmul, max, maximum, mean, median, meshgrid, min, minimum, moveaxis, multiply, nan_to_num, nanmean, nanmedian, nanquantile, nansum, negative, nextafter, nonzero, not_equal, ones, ones_like, outer, positive, pow, prod, promote_types, put, quantile, rad2deg, ravel, real, reciprocal, remainder, reshape, result_type, roll, rot90, round, row_stack, save, searchsorted, select, set_printoptions, sign, signbit, sin, sinc, sinh, sort, split, sqrt, square, squeeze, stack, std, subtract, sum, swapaxes, take, tan, tanh, tensordot, tile, trace, transpose, trapezoid, trapz, tril, tril_indices, triu, triu_indices, true_divide, trunc, typename, unique, unravel_index, vander, var, vdot, vsplit, vstack, where, zeros, zeros_like'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code: list functions that appear both in NumPy and PyTorch\n",
        "functions = lambda mod: set(f for f in dir(mod) if callable(getattr(mod, f)))\n",
        "\", \".join(sorted(functions(torch) & functions(np)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJi7wIQMw23"
      },
      "source": [
        "## 1.2 Hardware Acceleration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NZ2_KiAMw23"
      },
      "source": [
        "**Copiar tensores para a GPU** é simples no PyTorch, desde que sua máquina tenha GPU compatível e as bibliotecas necessárias estejam instaladas. No **Google Colab**, basta usar um **runtime com GPU** (Menu *Runtime* → *Change runtime type* → selecionar uma GPU, como **Nvidia T4**). Esse ambiente já vem com o PyTorch compilado com suporte a GPU, drivers e bibliotecas requeridas (por exemplo, **CUDA** e **cuDNN**).\n",
        "Se preferir rodar localmente, instale **drivers** e **bibliotecas** apropriadas seguindo as instruções: [https://homl.info/install-p](https://homl.info/install-p).\n",
        "\n",
        "O PyTorch tem excelente suporte a **GPUs Nvidia** e também a outros aceleradores:\n",
        "\n",
        "* **Apple MPS**: aceleração em **Apple Silicon** (M1, M2, posteriores) e alguns **Intel Macs** compatíveis.\n",
        "* **AMD**: **Instinct** e **Radeon** via **ROCm** (Linux) ou **DirectML** (Windows).\n",
        "* **Intel**: **GPUs e CPUs** (Linux/Windows) via **oneAPI**.\n",
        "* **Google TPUs**: integração via **`torch_xla`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_pZZJUHMw23",
        "outputId": "23a3c38c-0eab-4995-b3ba-27032cfd2c2f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtId7owqMw23"
      },
      "source": [
        "Em um Colab GPU Runtime, o dispositivo será igual a \"cuda\". Agora, vamos criar um tensor nessa GPU. Para isso, uma opção é criar o tensor na CPU e copiá-lo para a GPU usando o método **to()**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixGfCBcwMw24",
        "outputId": "40d3d532-8eab-4c1c-eda6-5c34ca49a30b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "M = M.to(device)\n",
        "M.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgxTG1_yMw24"
      },
      "source": [
        "Alternativamente, podemos criar o tensor diretamente na GPU usando o argumento do dispositivo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiJAQN6QMw24"
      },
      "outputs": [],
      "source": [
        "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVZQF1v4Mw24"
      },
      "source": [
        "Quando o tensor estiver na GPU, podemos executar operações nele normalmente, e todas elas ocorrerão na GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJryfyy6Mw24",
        "outputId": "e5f886d9-f507-4940-e989-c33284e4cefa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[14., 32.],\n",
              "        [32., 77.]], device='cuda:0')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "R = M @ M.T  # run some operations on the GPU\n",
        "R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YYjzFgwMw24"
      },
      "source": [
        "Quando um tensor é processado na **GPU**, o **resultado também permanece na GPU**. Isso permite **encadear várias operações** sem **copiar dados entre CPU e GPU**, evitando um gargalo comum de desempenho.\n",
        "\n",
        "**Quanto a GPU acelera?** Depende do **modelo da GPU** (as mais caras podem ser **dezenas de vezes** mais rápidas) e do **throughput de dados**:\n",
        "\n",
        "* **Modelos compute-heavy** (ex.: redes muito profundas): o **poder de cálculo** da GPU e a **quantidade de RAM** tendem a ser os fatores críticos.\n",
        "* **Modelos rasos / datasets grandes**: o **envio contínuo de dados** para a GPU pode virar o **gargalo** principal.\n",
        "\n",
        "O próximo trecho realiza um **teste comparando** a **multiplicação de matrizes** na **CPU vs GPU** para ilustrar essas diferenças de **tempo de execução** e **banda de dados**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9FkwWf3Mw24",
        "outputId": "8e201532-c054-4908-f1f4-a198098e07c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16.1 ms ± 2.17 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "549 µs ± 3.99 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "M = torch.rand((1000, 1000))  # on the CPU\n",
        "M @ M.T  # warmup\n",
        "%timeit M @ M.T\n",
        "\n",
        "M = M.to(device)\n",
        "M @ M.T  # warmup\n",
        "%timeit M @ M.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juSKiQuuMw25"
      },
      "source": [
        "No teste, a **GPU (Nvidia T4 no Colab)** proporcionou um **ganho de ~26×** na multiplicação de matrizes. Com GPUs mais potentes, o **speedup** tende a ser ainda maior. Porém, **em matrizes pequenas** (ex.: `100 × 100`), o ganho cai para algo como **~2×**.\n",
        "Isso ocorre porque **GPUs paralelizam tarefas grandes** (quebrando-as em muitas subtarefas para milhares de núcleos). **Tarefas pequenas** não geram paralelismo suficiente, reduzindo o benefício — e, em cenários com **muitas tarefas minúsculas**, **a CPU pode ser até mais rápida** devido ao overhead de orquestração na GPU.\n",
        "\n",
        "Com a base de **tensores** e **execução em CPU/GPU** estabelecida, o próximo passo é explorar o **autograd** do PyTorch (auto-diferenciação).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1EN0YQGMw25"
      },
      "source": [
        "## 1.3 Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QCs81x6Mw25"
      },
      "source": [
        " PyTorch implementa **auto-diferenciação em modo reverso** (*autograd*), permitindo calcular **gradientes automaticamente**. A ideia é simples de usar: dado, por exemplo, $f(x) = x^2$, o cálculo diferencial diz que $f'(x)=2x$. Avaliando em $f(5)$, obtemos $f(5)=25$ e $f'(5)=10$. O próximo trecho verifica esses valores com o **autograd** do PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJtUdQ42Mw25",
        "outputId": "e17c1fe2-1e6f-47e7-ae16-e00cdf2d0650"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(25., grad_fn=<PowBackward0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "f = x ** 2\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCEgNmqNMw25",
        "outputId": "10ef5a67-4393-43ba-cb37-8b3e9699b0a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXH6eZWDMw25"
      },
      "source": [
        "Obtivemos os valores corretos: **$f=25$** e **(x.\\texttt{grad}=10)**. A chamada `backward()` calculou automaticamente $f'(x)$ no ponto (x=5.0). Eis a lógica, linha a linha:\n",
        "\n",
        "* **Definição de variável com gradiente**\n",
        "  Criamos `x = 5.0` com `requires_grad=True`. Assim, o PyTorch **rastreia todas as operações** envolvendo `x`, construindo o **grafo de computação** necessário para executar o **backpropagation**. Nesse grafo, `x` é um **nó-folha**.\n",
        "\n",
        "* **Cálculo de $f = x ** 2$**\n",
        "  O resultado é `25.0`. Além do valor, `f` carrega o atributo **`grad_fn`** (ex.: `PowBackward0`), que **representa a operação** que gerou `f` e **informa como retropropagar** os gradientes por essa operação. É assim que o PyTorch **mantém o grafo**.\n",
        "\n",
        "* **Retropropagação**\n",
        "  `f.backward()` **propaga gradientes** a partir de `f` **até os nós-folha** (aqui, apenas `x`).\n",
        "\n",
        "* **Leitura do gradiente**\n",
        "  `x.grad` contém a **derivada de $f$ em relação a (x)**, computada no backprop (no exemplo, **10**).\n",
        "\n",
        "### Grafos dinâmicos (define-by-run)\n",
        "\n",
        "O PyTorch **cria o grafo on-the-fly** a cada *forward pass*, conforme as operações são executadas, o que suporta **modelos dinâmicos** com **loops e condicionais**.\n",
        "\n",
        "### Passo de gradiente (gradient descent) com `torch.no_grad()`\n",
        "\n",
        "Após obter gradientes, normalmente fazemos **descida do gradiente**, subtraindo uma fração do gradiente das variáveis do modelo. No exemplo de $f(x)=x^2$, isso **empurra (x) em direção a 0** (o minimizador).\n",
        "\n",
        "> Importante: **desative o rastreamento de gradiente** durante a atualização (por exemplo, usando `with torch.no_grad():`), pois **não queremos registrar** a própria atualização no grafo — e operações *in-place* em variáveis rastreadas podem **levantar exceção**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f340hQ5DMw26"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "with torch.no_grad():\n",
        "    x -= learning_rate * x.grad  # gradient descent step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgmJFVSJMw26",
        "outputId": "572535dc-9c9c-4b53-96aa-48cadecca140"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4., requires_grad=True)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGImkhoMMw26"
      },
      "source": [
        "No passo de **descida do gradiente**, (x) é decrementado por $0{,}1 \\times 10{,}0 = 1{,}0$, indo de **5,0** para **4,0**.\n",
        "\n",
        "Outra forma de **evitar cálculo de gradientes** é usar **`detach()`**: ele cria um **novo tensor desacoplado do grafo** (`requires_grad=False`), **apontando para os mesmos dados em memória**. Assim, você pode **atualizar esse tensor desacoplado** sem registrar a operação no grafo de computação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ieNXDSKMw26"
      },
      "outputs": [],
      "source": [
        "x_detached = x.detach()\n",
        "x_detached -= learning_rate * x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD0e55tYMw26"
      },
      "source": [
        "Como $x_{\\text{detached}}$ e $x$ **compartilham a mesma memória**, **alterar** $x_{\\text{detached}}$ também **altera** $x$.\n",
        "\n",
        "* **`detach()`**: útil quando você precisa **executar computações sem afetar os gradientes** (ex.: avaliação, logging) ou quando deseja **controle fino** sobre **quais operações** entram no cálculo de gradientes. Cria um **tensor desacoplado do grafo** ( `requires_grad=False` ), apontando para os **mesmos dados**.\n",
        "* **`no_grad()`**: geralmente **preferido** para **inferência** ou durante o **passo de descida do gradiente**, pois fornece um **contexto** conveniente que **desativa o rastreamento** de gradientes para tudo que estiver dentro do bloco.\n",
        "\n",
        "**Antes de repetir o ciclo** *(forward → backward → atualização)*, é **essencial zerar os gradientes** de **todos os parâmetros** do modelo, pois o PyTorch **acumula** gradientes por padrão. Não é necessário `no_grad()` para isso, já que os tensores de gradiente têm `requires_grad=False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayPQm6TWMw26",
        "outputId": "6abc4702-e7de-4828-c574-733467bc5dd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtZUNO-_Mw27"
      },
      "source": [
        "Juntando tudo, o ciclo de treinamento fica assim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtJzSV0TMw27"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "for iteration in range(100):\n",
        "    f = x ** 2  # forward pass\n",
        "    f.backward()  # backward pass\n",
        "    with torch.no_grad():\n",
        "        x -= learning_rate * x.grad  # gradient descent step\n",
        "    x.grad.zero_()  # reset the gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8XhO3lIMw27",
        "outputId": "eefff5f1-4d57-42ac-8edb-5aabd899e111"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0185e-09, requires_grad=True)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "846Pw9UvMw27"
      },
      "source": [
        "Operações **in-place** podem **economizar memória** e **evitar cópias**, mas **nem sempre** combinam bem com o **autograd**:\n",
        "\n",
        "1. **Proibição em nós-folha**\n",
        "   Você **não pode** aplicar uma operação *in-place* em um **nó-folha** (tensor com `requires_grad=True`). O PyTorch não saberia **onde armazenar** as informações do grafo. Exemplos que geram `RuntimeError`:\n",
        "\n",
        "   * `x.cos_()`\n",
        "   * `x += 1`\n",
        "\n",
        "2. **Risco de sobrescrever valores necessários ao backward**\n",
        "   Mesmo fora de nós-folha, operações *in-place* podem **apagar valores intermediários** que o autograd precisa para calcular gradientes, quebrando o **backpropagation**.\n",
        "\n",
        "**Exemplo a seguir no código**: calcular $z(t) = \\exp(t) + 1$ em $t=2$ e tentar obter os gradientes — veremos como certas escolhas *in-place* podem levar a erros durante o `backward()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZZ9Id4-Mw27"
      },
      "outputs": [],
      "source": [
        "#Novo\n",
        "\n",
        "t = torch.tensor(2.0, requires_grad=True)\n",
        "z = t.exp()  # this is an intermediate result\n",
        "z += 1  # this is an in-place operation\n",
        "z.backward()  # ⚠️ RuntimeError!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxau6VQnMw27"
      },
      "source": [
        "O valor de $z$ foi calculado corretamente, mas o `backward()` lançou `RuntimeError: one of the variables needed for gradient computation has been modified by an in-place operation`. Isso ocorreu porque o resultado intermediário $z = t.\\exp()$ foi **sobrescrito** por `z += 1`. No *backward*, ao chegar na **exp**, o autograd já não tinha o valor necessário para calcular o gradiente.\n",
        "\n",
        "**Correção simples:** troque `z += 1` por `z = z + 1`. Visualmente é parecido, mas **não é in-place**: cria-se **um novo tensor**, preservando o original no **grafo de computação**.\n",
        "\n",
        "---\n",
        "\n",
        "### Por que às vezes funciona? (ex.: com `cos()`)\n",
        "\n",
        "Se você trocar `exp()` por `cos()` no exemplo, o gradiente **funciona**. O motivo é **como cada operação é implementada** e **o que ela guarda** para o *backward*:\n",
        "\n",
        "* **Operações que salvam a *saída*** (não modifique a **saída** *in-place* antes do *backward*):\n",
        "  `exp()`, `relu()`, `rsqrt()`, `sigmoid()`, `sqrt()`, `tan()`, `tanh()`.\n",
        "\n",
        "* **Operações que salvam a *entrada*** (podem tolerar modificar a **saída**, mas **não** modifique a **entrada** *in-place* antes do *backward*):\n",
        "  `abs()`, `cos()`, `log()`, `sin()`, `square()`, `var()`.\n",
        "\n",
        "* **Operações que salvam *entrada e saída*** (não modifique **nenhuma** delas *in-place*):\n",
        "  `max()`, `min()`, `norm()`, `prod()`, `sgn()`, `std()`.\n",
        "\n",
        "* **Operações que não salvam nem entrada nem saída** (seguro modificar *in-place*):\n",
        "  `ceil()`, `floor()`, `mean()`, `round()`, `sum()`.\n",
        "\n",
        "> **Regra prática:** quando usar operações *in-place* para economizar memória, verifique **o que a operação salva** para o *backward*. Se você alterar *in-place* algo que o autograd precisa (entrada, saída ou ambos), o gradiente **quebrará**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQUoS6tAMw27"
      },
      "source": [
        "OK, vamos voltar um pouco. Já discutimos todos os fundamentos do PyTorch: como criar tensores e usá-los para realizar todos os tipos de cálculos, como acelerar os cálculos com uma GPU e como usar o Autograd para calcular gradientes para gradiente descendente. Ótimo! Agora, vamos aplicar o que aprendemos até agora, construindo e treinando um modelo de regressão linear simples com o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onSCzQ-ZMw28"
      },
      "source": [
        "# 2. Implementing Linear Regression\n",
        "\n",
        "Começaremos implementando a regressão linear usando tensores e autograd diretamente, depois simplificaremos o código usando a API de alto nível do PyTorch e também adicionaremos suporte à GPU.\n",
        "\n",
        "## 2.1 Linear Regression Using Tensors & Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwjpxLu3Mw28"
      },
      "source": [
        "Usaremos o **California Housing** (como no Cap. 9). Suponha que os dados já foram baixados com `sklearn.datasets.fetch_california_housing()` e divididos com `train_test_split()` em: `X_train`, `y_train`, `X_valid`, `y_valid`, `X_test`, `y_test`.\n",
        "\n",
        "Agora vamos **converter tudo para tensores** e **normalizar** usando **operações de tensor** (em vez de `StandardScaler`), para praticar PyTorch:\n",
        "\n",
        "* **Estatísticas no treino**: calcule **média** $\\mu_{\\text{train}}$ e **desvio-padrão** $\\sigma_{\\text{train}}$ apenas em `X_train`.\n",
        "* **Padronização**: aplique em todos os *splits* a transformação\n",
        "  $$\\tilde{X}=\\frac{X-\\mu_{\\text{train}}}{\\sigma_{\\text{train}}}$$\n",
        "\n",
        "Isso garante padronização consistente e evita **vazamento de informação**. O próximo trecho mostra a **conversão para tensores** e a **normalização** passo a passo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDc0As07Mw28"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsI8MU1QMw28"
      },
      "outputs": [],
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_valid = torch.FloatTensor(X_valid)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "means = X_train.mean(dim=0, keepdims=True)\n",
        "stds = X_train.std(dim=0, keepdims=True)\n",
        "X_train = (X_train - means) / stds\n",
        "X_valid = (X_valid - means) / stds\n",
        "X_test = (X_test - means) / stds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWVxNBooMw28"
      },
      "source": [
        "Também precisamos **converter os alvos para tensores**. Como as **predições** serão **vetores-coluna** (matrizes com **uma única coluna**), os **alvos** devem ter o **mesmo formato**. Porém, no NumPy os alvos vêm **unidimensionais**; portanto, é necessário **reestruturar** para **adicionar uma 2ª dimensão de tamanho 1**, formando vetores-coluna (isto é, shape $[N,,1]$).\n",
        "\n",
        "> Em resumo: converta `y_*` para tensores e **reshape** para $[N,,1]$ para alinhar com as **saídas do modelo**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5IOFfdKMw28"
      },
      "outputs": [],
      "source": [
        "y_train = torch.FloatTensor(y_train).view(-1, 1)\n",
        "y_valid = torch.FloatTensor(y_valid).view(-1, 1)\n",
        "y_test = torch.FloatTensor(y_test).view(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNI_wdwkMw28"
      },
      "source": [
        "Agora que os dados estão prontos, vamos criar os parâmetros do nosso modelo de regressão linear:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1D5vwtXMw28"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "n_features = X_train.shape[1]  # there are 8 input features\n",
        "w = torch.randn((n_features, 1), requires_grad=True)\n",
        "b = torch.tensor(0., requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgbc7G1LMw29"
      },
      "source": [
        "Definimos um vetor de **pesos** $w$ (vetor-coluna com **um peso por atributo de entrada**, aqui $8$) e um **viés** escalar $b$. Os **pesos são inicializados aleatoriamente** e o **viés em zero**. Embora, neste caso simples, também pudéssemos zerar $w$, é boa prática **inicializar pesos aleatoriamente** para **quebrar a simetria** entre unidades — princípio crucial em **redes neurais** (Cap. 9). Adotar esse hábito desde já facilita a transição para modelos mais profundos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PV6jeC_Mw29"
      },
      "source": [
        "Em seguida, vamos treinar nosso modelo, de forma muito semelhante à que fizemos no Capítulo 4, exceto que usaremos o autodiff para calcular os gradientes em vez de usar uma equação de forma fechada. Por enquanto, usaremos a descida do gradiente em lote (BGD), utilizando o conjunto de treinamento completo em cada etapa:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mZrqQziMw29"
      },
      "source": [
        "### Laço de treino: passo a passo (regressão linear)\n",
        "\n",
        "* **Taxa de aprendizado (`learning_rate`)**\n",
        "  Definimos o hiperparâmetro de **taxa de aprendizado**; experimente valores para equilibrar **convergência** e **precisão**.\n",
        "\n",
        "* **Épocas (20)**\n",
        "  Executamos **20 épocas**. Poderíamos aplicar **early stopping** (Cap. 4), mas aqui mantemos simples.\n",
        "\n",
        "* **Forward pass**\n",
        "  Calculamos as **predições** $y_{\\text{pred}}$ e a **loss MSE**:\n",
        "  $$\\mathrm{MSE}(y,\\hat y)=\\frac{1}{N}\\sum_{i=1}^{N}\\bigl(y_i-\\hat y_i\\bigr)^2.$$\n",
        "\n",
        "* **Autograd**\n",
        "  `loss.backward()` calcula **gradientes** da loss em relação a **todos os parâmetros**.\n",
        "\n",
        "* **Passo de descida do gradiente**\n",
        "  Usamos `b.grad` e `w.grad` para **atualizar** os parâmetros **dentro de** `with torch.no_grad():`.\n",
        "\n",
        "* **Zerar gradientes (essencial!)**\n",
        "  Após atualizar, **zeramos os gradientes** para não acumulá-los na próxima iteração.\n",
        "\n",
        "* **Logging**\n",
        "  Imprimimos **nº da época** e a **loss**; `item()` extrai o valor escalar.\n",
        "\n",
        "> Regra prática de formatação: **código** → `backticks`; **fórmulas** → `$...$`; se precisar de sublinhado em modo math, use `\\_`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjwsYhXVMw29",
        "outputId": "7b640c96-10b0-4667-82f8-b3b91fbd46c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 16.158456802368164\n",
            "Epoch 2/20, Loss: 4.8793745040893555\n",
            "Epoch 3/20, Loss: 2.255225419998169\n",
            "Epoch 4/20, Loss: 1.3307634592056274\n",
            "Epoch 5/20, Loss: 0.9680691957473755\n",
            "Epoch 6/20, Loss: 0.8142675757408142\n",
            "Epoch 7/20, Loss: 0.7417045831680298\n",
            "Epoch 8/20, Loss: 0.7020701169967651\n",
            "Epoch 9/20, Loss: 0.6765918731689453\n",
            "Epoch 10/20, Loss: 0.6577965021133423\n",
            "Epoch 11/20, Loss: 0.6426151990890503\n",
            "Epoch 12/20, Loss: 0.6297222971916199\n",
            "Epoch 13/20, Loss: 0.6184942126274109\n",
            "Epoch 14/20, Loss: 0.6085968613624573\n",
            "Epoch 15/20, Loss: 0.5998216867446899\n",
            "Epoch 16/20, Loss: 0.592018723487854\n",
            "Epoch 17/20, Loss: 0.5850691795349121\n",
            "Epoch 18/20, Loss: 0.578873336315155\n",
            "Epoch 19/20, Loss: 0.573345422744751\n",
            "Epoch 20/20, Loss: 0.5684100389480591\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.4\n",
        "n_epochs = 20\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = X_train @ w + b\n",
        "    loss = ((y_pred - y_train) ** 2).mean()\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        b -= learning_rate * b.grad\n",
        "        w -= learning_rate * w.grad\n",
        "        b.grad.zero_()\n",
        "        w.grad.zero_()\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxSk1y7wMw29"
      },
      "source": [
        "Parabéns, você acabou de treinar seu primeiro modelo usando o PyTorch! Agora você pode usar o modelo para fazer previsões para alguns novos dados X_new (que devem ser representados como um tensor do PyTorch). Por exemplo, vamos fazer previsões para as três primeiras instâncias do conjunto de teste:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmXpYWi_Mw29"
      },
      "outputs": [],
      "source": [
        "X_new = X_test[:3]  # pretend these are new instances\n",
        "with torch.no_grad():\n",
        "    y_pred = X_new @ w + b  # use the trained parameters to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo8uiLVIMw29",
        "outputId": "a2a570df-b71b-40b4-e7f1-bf77df459d94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8916],\n",
              "        [1.6480],\n",
              "        [2.6577]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L95N6f4HMw2-"
      },
      "source": [
        "Implementar a regressão linear usando a API de baixo nível do PyTorch não foi tão difícil, mas usar essa abordagem para modelos mais complexos seria muito complicado e trabalhoso. Portanto, o PyTorch oferece uma API de alto nível para simplificar tudo isso. Vamos reescrever nosso modelo usando essa API de alto nível."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCoQfDWYMw2-"
      },
      "source": [
        "## 2.2 Linear Regression Using PyTorch's High-Level API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xng8UX3AMw2-"
      },
      "source": [
        "PyTorch fornece uma implementação de regressão linear na classe `torch.nn.Linear`, então vamos usá-la\n",
        "> **nn = *neural network(s)*** (“rede(s) neural(is)”)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixb98sneMw2-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(42)  # to get reproducible results\n",
        "model = nn.Linear(in_features=n_features, out_features=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ITkWd4iMw2-"
      },
      "source": [
        "`nn.Linear` (atalho de `torch.nn.Linear`) é um **módulo** do PyTorch; todo módulo herda de `nn.Module`. Para **regressão linear simples**, **um único** `nn.Linear` já basta. Em redes neurais reais, você **empilha vários módulos** — pense neles como **“LEGOs matemáticos”**.\n",
        "\n",
        "**Parâmetros internos do `nn.Linear`:**\n",
        "\n",
        "* **Viés**: vetor de **bias** com **um termo por neurônio**.\n",
        "* **Pesos**: **matriz de pesos** com **uma linha por neurônio** e **uma coluna por dimensão de entrada** (ou seja, é a **transposta** da matriz/vetor de pesos usada anteriormente no capítulo e na equação abaixo).\n",
        "\n",
        "No nosso caso, com `out_features=1`, o modelo tem **um único neurônio**:\n",
        "\n",
        "* O vetor de **bias** tem **um único termo**.\n",
        "* A **matriz de pesos** tem **uma única linha**.\n",
        "\n",
        "Esses parâmetros ficam acessíveis **diretamente** como **atributos** do módulo:\n",
        "\n",
        "* `linear.weight`  → matriz de pesos $W$\n",
        "* `linear.bias`    → viés $b$\n",
        "\n",
        "> Intuição: o módulo implementa $,y = XW^\\top + b,$ (com $W$ armazenado como **linha** quando há um neurônio de saída), mantendo os parâmetros **dentro do módulo** para integração com o **autograd** e os **otimizadores**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaQrh3HLMw2-"
      },
      "source": [
        "<div align=\"center\" style=\"margin-top:20px; margin-bottom:20px;\">\n",
        "  \n",
        "![pt](Aula_Imagens\\eq_Percep.png)\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDGsHq2cMw2-",
        "outputId": "6bd0dd0e-f2e6-4b98-e9bb-a49211c3ed16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.3117], requires_grad=True)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN93Z7m5Mw2-",
        "outputId": "dac92468-63cd-40aa-cc6d-f4e3c88d1d6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5EMDyRDMw2_"
      },
      "source": [
        "### Parâmetros em `nn.Linear`: inicialização, `Parameter` e iteração\n",
        "\n",
        "* **Inicialização aleatória + reprodutibilidade**\n",
        "  Os **dois parâmetros** do módulo (`weight` e `bias`) são **inicializados aleatoriamente** por padrão — por isso utilizamos `manual_seed()` para obter **resultados reprodutíveis**.\n",
        "\n",
        "* **`torch.nn.Parameter` vs tensor comum**\n",
        "  Esses parâmetros são instâncias de **`torch.nn.Parameter`**, que **herda** de `tensor.Tensor`.\n",
        "  ➤ Consequência: você pode **usá-los como tensores normais** (mesmas operações), **mas** o PyTorch os **registra automaticamente** como **parâmetros treináveis** do módulo (para autograd e otimizadores).\n",
        "  **Diferença central:** um **`Parameter`** é um **tensor marcado** para ser **rastreado como parâmetro do modelo**; já um **tensor comum**, mesmo com `requires_grad=True`, **não** é listado como parâmetro do módulo.\n",
        "\n",
        "* **`module.parameters()` (recursivo)**\n",
        "  O método **`parameters()`** retorna um **iterador** sobre **todos os atributos do tipo `Parameter`** do módulo **e de seus submódulos (recursivamente)**.\n",
        "  Não retorna **tensores comuns**, mesmo que tenham `requires_grad=True`.\n",
        "\n",
        "> Em resumo: **`Parameter` = tensor treinável do módulo** (aparece em `parameters()` e nos otimizadores); **tensor comum** pode participar do grafo, mas **não** é tratado como **parâmetro do modelo**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uApY7S5IMw2_",
        "outputId": "61386283-c876-48d3-e485-d9094847ddac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.3117], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwlIa1WNMw2_"
      },
      "source": [
        "* **Parâmetros nomeados**\n",
        "  Além de `parameters()`, há **`named_parameters()`**, que retorna um **iterador de pares (nome, parâmetro)**. Útil para **inspeção**, **debug** e **logs** (ex.: imprimir gradientes por nome).\n",
        "\n",
        "* **Chamando o módulo como função**\n",
        "  Um **módulo** (`nn.Module`) pode ser **chamado como função**: internamente ele executa o método `forward`.\n",
        "  Exemplo: passar as **duas primeiras instâncias** do *training set* ao modelo para obter **predições** iniciais.\n",
        "\n",
        "  > Como os **parâmetros ainda estão aleatórios**, as **predições serão ruins** — o comportamento esperado **antes do treino**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Iv1T68EMw2_",
        "outputId": "01c6c679-47eb-4e69-b0dc-baf556b0f683"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.4718],\n",
              "        [ 0.1131]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(X_train[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC54OhpJMw2_"
      },
      "source": [
        "Ao usar um **módulo como função**, o PyTorch chama internamente seu **`forward()`**. No caso de `nn.Linear`, ele computa:\n",
        "[\n",
        "X ;@; W^\\top ;+; b\n",
        "]\n",
        "onde $X$ é a entrada, $W$ é `self.weight` e $b$ é `self.bias` — **exatamente** o que precisamos para **regressão linear**.\n",
        "\n",
        "O tensor de saída traz o atributo **`grad_fn`**, indicando que o **autograd** rastreou o **grafo de computação** durante as predições.\n",
        "\n",
        "**Próximo passo:** com o modelo definido, precisamos criar um **otimizador** (para **atualizar os parâmetros**) e escolher uma **função de perda** (loss).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P7N91PDMw2_"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctt7-v_iMw2_"
      },
      "source": [
        "O PyTorch oferece **diversos otimizadores** (detalhes no próximo capítulo). Aqui usamos o **SGD** (*stochastic gradient descent*), que atende a **SGD puro**, **mini-batch GD** e **batch GD**. Para inicializá-lo, passamos os **parâmetros do modelo** (por exemplo, `model.parameters()`) e a **taxa de aprendizado** (`lr`).\n",
        "\n",
        "Para a **função de perda**, instanciamos **`nn.MSELoss`**. Ela também é um **módulo**, então pode ser usada **como função**: recebe **predições** e **alvos** e calcula a **MSE**,\n",
        "\n",
        "  $$\\mathrm{MSE}(y,\\hat y)=\\frac{1}{N}\\sum_{i=1}^{N}\\bigl(y_i-\\hat y_i\\bigr)^2.$$\n",
        "  \n",
        "O submódulo `nn` inclui **muitas outras perdas** e utilidades de redes neurais.\n",
        "\n",
        "**A seguir:** escreveremos uma **função de treino** compacta para executar o ciclo *forward → loss → backward → update*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxtH7imZMw3A"
      },
      "outputs": [],
      "source": [
        "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
        "    for epoch in range(n_epochs):\n",
        "        y_pred = model(X_train)\n",
        "        loss = criterion(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnItmklvMw3A"
      },
      "source": [
        "### Comparando os laços de treino: baixo nível vs. alto nível (`nn` + `optim`)\n",
        "\n",
        "O novo laço é **quase idêntico** ao anterior, porém agora usamos **abstrações de nível mais alto** (módulos `nn` e otimizadores `optim`) em vez de manipular diretamente **tensores** e **autograd**. Pontos-chave:\n",
        "\n",
        "* **Critério (loss function “objeto”)**\n",
        "  Em PyTorch, é comum chamar o **objeto** de função de perda de **criterion** (para distinguir do **valor da loss** calculado a cada iteração).\n",
        "  Aqui, o **criterion** é uma instância de `nn.MSELoss`.\n",
        "\n",
        "* **`optimizer.step()`**\n",
        "  Substitui as duas linhas manuais que **atualizavam** $b$ e $w$ no código anterior (descida do gradiente).\n",
        "\n",
        "* **`optimizer.zero_grad()`**\n",
        "  Substitui as duas linhas que **zeravam** `b.grad` e `w.grad`.\n",
        "  Observação: **não é necessário** usar `with torch.no_grad():` aqui — o **otimizador** já trata corretamente o **rastro de gradientes** internamente em `step()` e `zero_grad()`.\n",
        "\n",
        "**Próximo passo:** chamar a **função de treino** para ajustar o modelo e observar a **queda da loss** ao longo das épocas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P-9nTClMw3A",
        "outputId": "d7c5946e-4744-4a55-81ea-7a5f2840fcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 4.3378496170043945\n",
            "Epoch 2/20, Loss: 0.7802939414978027\n",
            "Epoch 3/20, Loss: 0.6253842115402222\n",
            "Epoch 4/20, Loss: 0.6060433983802795\n",
            "Epoch 5/20, Loss: 0.5956299304962158\n",
            "Epoch 6/20, Loss: 0.587356686592102\n",
            "Epoch 7/20, Loss: 0.5802990794181824\n",
            "Epoch 8/20, Loss: 0.5741382837295532\n",
            "Epoch 9/20, Loss: 0.5687101483345032\n",
            "Epoch 10/20, Loss: 0.5639079809188843\n",
            "Epoch 11/20, Loss: 0.5596511363983154\n",
            "Epoch 12/20, Loss: 0.5558737516403198\n",
            "Epoch 13/20, Loss: 0.5525194406509399\n",
            "Epoch 14/20, Loss: 0.5495392084121704\n",
            "Epoch 15/20, Loss: 0.5468900203704834\n",
            "Epoch 16/20, Loss: 0.544533908367157\n",
            "Epoch 17/20, Loss: 0.5424376726150513\n",
            "Epoch 18/20, Loss: 0.5405716300010681\n",
            "Epoch 19/20, Loss: 0.5389097332954407\n",
            "Epoch 20/20, Loss: 0.5374288558959961\n"
          ]
        }
      ],
      "source": [
        "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcysEhPWMw3A"
      },
      "source": [
        "Tudo bem; o modelo foi treinado e agora você pode usá-lo para fazer previsões simplesmente chamando-o como uma função (de preferência dentro de um contexto no_grad(), como vimos anteriormente):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kgKQv2mMw3A",
        "outputId": "88c56f54-ed1a-4abf-9b0a-b0b2595e7cbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8061],\n",
              "        [1.7116],\n",
              "        [2.6973]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_new = X_test[:3]  # pretend these are new instances\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_new)  # use the trained model to make predictions\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjH6re_QMw3A"
      },
      "source": [
        "As **predições** ficam **semelhantes**, mas **não idênticas** às do modelo anterior porque o `nn.Linear` **inicializa os parâmetros de forma diferente**: usa uma **distribuição uniforme** em um **intervalo específico** tanto para os **pesos** quanto para o **viés** (detalhes sobre inicialização serão tratados no **Cap. 11**).\n",
        "\n",
        "Com essa **API de alto nível** dominada, estamos prontos para ir além da **regressão linear** e construir um **perceptron multicamadas (MLP)**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WehfQp3vMw3A"
      },
      "source": [
        ">______________________Aula 34"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KXdNZOvMw3A"
      },
      "source": [
        "# 3. Implementing a Regression MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GExerbMhN4Fs"
      },
      "source": [
        "## `nn.Sequential` no PyTorch\n",
        "\n",
        "O PyTorch oferece o módulo **`nn.Sequential`**, que permite encadear múltiplos módulos de forma automática:\n",
        "\n",
        "- Ao passar uma entrada para um módulo `nn.Sequential`, ela é processada pelo **primeiro módulo**.\n",
        "- A saída do primeiro módulo é então enviada para o **segundo módulo**, e assim por diante até o último módulo.\n",
        "\n",
        "Esse recurso é especialmente útil porque muitas redes neurais são essencialmente **pilhas de módulos**, tornando o `nn.Sequential` um dos módulos mais importantes do PyTorch.\n",
        "\n",
        "No caso de um **MLP (Perceptron Multicamadas)**, ele pode ser construído como uma simples sequência de módulos: duas camadas ocultas seguidas de uma camada de saída.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTHnm1lOMw3B"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kDUNu6AMw3B"
      },
      "source": [
        "* **Camada 1 (entrada → oculta 1)**\n",
        "\n",
        "  * **Entradas**: $n_{\\text{features}}$ (aqui, **8**).\n",
        "  * **Saídas**: **50** (hiperparâmetro ajustável).\n",
        "\n",
        "* **Ativação 1** — `nn.ReLU`\n",
        "\n",
        "  * **Sem parâmetros**; atua **elemento a elemento**; **não** altera o *shape* (apenas os valores).\n",
        "\n",
        "* **Camada 2 (oculta 1 → oculta 2)**\n",
        "\n",
        "  * **Entradas**: **50** (deve **casar** com a saída da camada anterior).\n",
        "  * **Saídas**: **40** (poderia ser igual à anterior, mas aqui usamos 40 para enfatizar a **compatibilidade entre camadas**).\n",
        "\n",
        "* **Ativação 2** — `nn.ReLU`\n",
        "\n",
        "  * Mesmas observações: **sem parâmetros**, **itemwise**, **shape** preservado.\n",
        "\n",
        "* **Camada de saída (oculta 2 → saída)**\n",
        "\n",
        "  * **Entradas**: **40** (devem **casar** com a camada anterior).\n",
        "  * **Saídas**: devem **igualar a dimensionalidade dos alvos**. Como o alvo é **unidimensional**, usamos **1**.\n",
        "\n",
        "> Regra prática: a **saída de uma camada** deve **combinar** com a **entrada da próxima**; apenas a **última camada** é **restrita pelos alvos**.\n",
        "> A seguir: **treinar o modelo** exatamente como antes (definir *criterion*, *optimizer*, laço de épocas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGB_3SIwMw3B",
        "outputId": "7f45a3a7-b8c3-4eca-8af0-82c6b0ee71a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 5.045480251312256\n",
            "Epoch 2/20, Loss: 2.0523123741149902\n",
            "Epoch 3/20, Loss: 1.0039883852005005\n",
            "Epoch 4/20, Loss: 0.8570139408111572\n",
            "Epoch 5/20, Loss: 0.7740675210952759\n",
            "Epoch 6/20, Loss: 0.7225847244262695\n",
            "Epoch 7/20, Loss: 0.6893726587295532\n",
            "Epoch 8/20, Loss: 0.6669032573699951\n",
            "Epoch 9/20, Loss: 0.6507738828659058\n",
            "Epoch 10/20, Loss: 0.6383934020996094\n",
            "Epoch 11/20, Loss: 0.6281993389129639\n",
            "Epoch 12/20, Loss: 0.6193399429321289\n",
            "Epoch 13/20, Loss: 0.6113173365592957\n",
            "Epoch 14/20, Loss: 0.6038705706596375\n",
            "Epoch 15/20, Loss: 0.5968307852745056\n",
            "Epoch 16/20, Loss: 0.5901119112968445\n",
            "Epoch 17/20, Loss: 0.5836468935012817\n",
            "Epoch 18/20, Loss: 0.5774063467979431\n",
            "Epoch 19/20, Loss: 0.5713554620742798\n",
            "Epoch 20/20, Loss: 0.565444827079773\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()\n",
        "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j554r0KrMw3B"
      },
      "source": [
        "Parabéns: você **treinou sua primeira rede neural no PyTorch**! 🎉\n",
        "Mas ainda estamos usando **batch gradient descent**: a cada iteração, calculamos **gradientes sobre **todo** o conjunto de treino**. Isso funciona para **datasets pequenos**, porém **não escala** bem para **dados/modelos grandes**.\n",
        "\n",
        "**Próximo passo:** migrar para **mini-batch gradient descent**, isto é, **particionar** o treinamento em **lotes menores** (mini-batches). Benefícios principais:\n",
        "\n",
        "* **Eficiência computacional**: melhor uso de **GPU/CPU** e **memória**.\n",
        "* **Atualizações mais frequentes**: gradientes **mais ruidosos**, porém **mais rápidos**, acelerando a convergência prática.\n",
        "* **Escalabilidade**: viabiliza treinar com **datasets massivos** e **modelos maiores**.\n",
        "\n",
        "> Ideia central: trocamos “um gradiente caro por época” por “**vários gradientes baratos por época**”, mantendo bom progresso e reduzindo o custo por iteração.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzlwOaTqMw3B"
      },
      "source": [
        "# 4. Implementing Mini-Batch Gradient Descent using DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnR5Ql4JtChY"
      },
      "source": [
        "## Carregando Mini-Batches com `DataLoader`\n",
        "\n",
        "Para facilitar a implementação do **Gradient Descent em mini-batches**, o PyTorch oferece a classe **`DataLoader`**, disponível em `torch.utils.data`.  \n",
        "Ela permite:\n",
        "\n",
        "- Carregar os dados em **lotes (batches)** de forma eficiente;\n",
        "- **Embaralhar** os dados a cada época, quando desejado.\n",
        "\n",
        "O `DataLoader` precisa receber um **dataset** que possua duas funções:\n",
        "\n",
        "- `__len__()` → retorna o número de amostras;\n",
        "- `__getitem__(index)` → retorna uma amostra específica (entrada + alvo).\n",
        "\n",
        "Como nossos dados já estão nos tensores `X_train` e `y_train`, podemos usar a classe **`TensorDataset`**, que encapsula os tensores e fornece a interface necessária.\n",
        "\n",
        "Após isso, utilizamos o `DataLoader` para extrair os mini-batches do dataset, incluindo a opção `shuffle=True` para embaralhar as amostras durante o treinamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sji9HNxLMw3B"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNNzBLMSzFBb"
      },
      "source": [
        "Com um modelo maior e o treinamento sendo feito em mini-batches, é recomendável utilizar **aceleração por hardware** (GPU).  \n",
        "A abordagem é direta:\n",
        "\n",
        "- O modelo deve ser **movido para a GPU**, usando o método `.to()`, o que transfere todos os seus parâmetros para a memória da GPU.\n",
        "- A cada iteração de treinamento, o **batch também deve ser copiado para a GPU** antes do processamento.\n",
        "\n",
        "Além disso, após mover o modelo, podemos definir a **função de perda** e o **otimizador** normalmente, porém com um **learning rate menor** (por exemplo, `0.02`), já que modelos maiores exigem ajustes mais cuidadosos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5Auwdw_Mw3C"
      },
      "outputs": [],
      "source": [
        "# extra code – build the model just like earlier\n",
        "torch.manual_seed(42)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50), nn.ReLU(),\n",
        "    nn.Linear(50, 40), nn.ReLU(),\n",
        "    nn.Linear(40, 1)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# extra code – build the optimizer and loss function, as earlier\n",
        "learning_rate = 0.02\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQoepnzyzeqh"
      },
      "source": [
        "Para treinar o modelo utilizando **mini-batch Gradient Descent**, definimos uma função `train()` responsável por:\n",
        "\n",
        "- Iterar sobre os batches fornecidos pelo `DataLoader`;\n",
        "- Enviar os dados para a GPU antes do processamento;\n",
        "- Executar as etapas do treinamento em cada batch:\n",
        "  - Forward pass\n",
        "  - Cálculo da perda\n",
        "  - Backpropagation\n",
        "  - Atualização dos parâmetros\n",
        "\n",
        "Essa função organiza o processo de treinamento de forma clara e reutilizável, mantendo o fluxo eficiente com uso de mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ibG0e8JMw3C"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-55fanttzvP8"
      },
      "source": [
        "Durante o treinamento, a função percorre todo o conjunto de treinamento **época por época**, processando cada batch de forma sequencial, como já visto.\n",
        "\n",
        "A primeira linha da função é:\n",
        "\n",
        "- **`model.train()`**  \n",
        "  - Coloca o modelo (e todos os seus submódulos) em **modo de treinamento**.\n",
        "  - Por enquanto, isso não muda nada no comportamento das camadas que estamos usando.\n",
        "  - Porém, será essencial quando utilizarmos camadas como:\n",
        "    - `nn.Dropout`\n",
        "    - `nn.BatchNorm1d`\n",
        "  - Essas camadas **se comportam de maneira diferente** no treinamento e na avaliação.\n",
        "\n",
        "Para usar o modelo fora do treinamento, como em avaliação ou previsão:\n",
        "\n",
        "- **`model.eval()`** deve ser chamado primeiro.\n",
        "- O atributo **`model.training`** indica se o modelo está no modo de treinamento (`True`) ou avaliação (`False`).\n",
        "\n",
        "---\n",
        "\n",
        "### Observação Importante\n",
        "\n",
        "O PyTorch **não fornece** um loop de treinamento pronto.  \n",
        "Você precisa implementá-lo manualmente — o que oferece:\n",
        "\n",
        "✅ Mais controle  \n",
        "✅ Maior clareza  \n",
        "✅ Flexibilidade total\n",
        "\n",
        "Caso prefira um loop mais completo e automatizado, existem bibliotecas baseadas em PyTorch que fornecem:\n",
        "\n",
        "- suporte a multi-GPU\n",
        "- callbacks\n",
        "- logging de métricas\n",
        "- treinamento estruturado\n",
        "\n",
        "📦 Exemplos:\n",
        "- **PyTorch Lightning**\n",
        "- **FastAI**\n",
        "- **Catalyst**\n",
        "- **Keras** (desde a versão 3, também com suporte a PyTorch e JAX)\n",
        "\n",
        "---\n",
        "\n",
        "Após definir a função `train()`, basta chamá-la para iniciar o treinamento do modelo na GPU.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7eTytt5Mw3C",
        "outputId": "52e34667-d40d-4ac8-85f9-7733618cc693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.5900\n",
            "Epoch 2/20, Loss: 0.4046\n",
            "Epoch 3/20, Loss: 0.3801\n",
            "Epoch 4/20, Loss: 0.3629\n",
            "Epoch 5/20, Loss: 0.3529\n",
            "Epoch 6/20, Loss: 0.3520\n",
            "Epoch 7/20, Loss: 0.3408\n",
            "Epoch 8/20, Loss: 0.3427\n",
            "Epoch 9/20, Loss: 0.3406\n",
            "Epoch 10/20, Loss: 0.3378\n",
            "Epoch 11/20, Loss: 0.3304\n",
            "Epoch 12/20, Loss: 0.3267\n",
            "Epoch 13/20, Loss: 0.3244\n",
            "Epoch 14/20, Loss: 0.3221\n",
            "Epoch 15/20, Loss: 0.3186\n",
            "Epoch 16/20, Loss: 0.3149\n",
            "Epoch 17/20, Loss: 0.3123\n",
            "Epoch 18/20, Loss: 0.3111\n",
            "Epoch 19/20, Loss: 0.3088\n",
            "Epoch 20/20, Loss: 0.3072\n"
          ]
        }
      ],
      "source": [
        "train(model, optimizer, mse, train_loader, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJv-79SCMw3C"
      },
      "source": [
        "# 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DX7TKvA0RmL"
      },
      "source": [
        "Para avaliar o desempenho do modelo em um conjunto de dados específico, é criada uma função que:\n",
        "\n",
        "- Recebe o **modelo** e um **DataLoader** contendo os dados de avaliação.\n",
        "- Utiliza uma **função de métrica** para calcular o desempenho em cada batch.\n",
        "- Utiliza uma **função de agregação** (por padrão, a média) para combinar as métricas dos batches e obter o valor final.\n",
        "\n",
        "Essa estrutura permite avaliar o modelo de maneira eficiente, processando os dados em mini-batches e garantindo que o cálculo das métricas seja flexível e reutilizável.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6rB7GxPMw3C"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
        "    model.eval()\n",
        "    metrics = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric = metric_fn(y_pred, y_batch)\n",
        "            metrics.append(metric)\n",
        "    return aggregate_fn(torch.stack(metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKkVJjY16yi2"
      },
      "source": [
        "Para calcular o **MSE (Mean Squared Error)** no conjunto de validação:\n",
        "\n",
        "1. Criar um **TensorDataset** a partir dos tensores de validação `X_valid` e `y_valid`.\n",
        "2. Criar um **DataLoader** para iterar sobre o dataset de validação em mini-batches.\n",
        "3. Passar o DataLoader para a função `evaluate()` junto com a métrica desejada.\n",
        "\n",
        "Dessa forma, podemos calcular eficientemente a métrica de validação sem afetar o modelo treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnOZYcyRMw3C",
        "outputId": "ffd36aa2-dd9f-47a4-8669-704c9e29f744"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.4080, device='cuda:0')"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "valid_mse = evaluate(model, valid_loader, mse)\n",
        "valid_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjfCXLPp7RlI"
      },
      "source": [
        "Se quisermos utilizar o **RMSE (Root Mean Squared Error)** ao invés do MSE:\n",
        "\n",
        "- O PyTorch não fornece uma função pronta para RMSE.\n",
        "- No entanto, podemos implementar facilmente a função de métrica personalizada:\n",
        "\n",
        "  - Calcular o MSE de cada batch\n",
        "  - Aplicar a **raiz quadrada** do resultado\n",
        "\n",
        "Isso permite obter uma métrica mais interpretável, já que o RMSE está na mesma escala dos valores previstos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV3Lbqb2Mw3C",
        "outputId": "9491819d-5dd2-4766-b923-1b173931859e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.5668, device='cuda:0')"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def rmse(y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).mean().sqrt()\n",
        "\n",
        "evaluate(model, valid_loader, rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-HgfMMO8kvj"
      },
      "source": [
        "O RMSE deveria ser igual à raiz quadrada do MSE. No entanto, ao calcular a raiz quadrada do MSE obtido anteriormente, podemos perceber que o resultado é diferente do esperado.\n",
        "\n",
        "Isso acontece porque o MSE pode ter sido calculado como a média das perdas de cada batch, e tirar a raiz dessa média não é o mesmo que calcular o RMSE de cada batch individualmente e depois agregar.  \n",
        "\n",
        "Portanto, é importante definir claramente como a métrica será agregada ao usar o RMSE para garantir resultados consistentes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Is this conversation helpful so far?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38HiYl4DMw3C",
        "outputId": "ec183c2d-1736-44bb-a0ab-f80ac1a3023b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6388, device='cuda:0')"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_mse.sqrt()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7v3Kqwd9s1d"
      },
      "source": [
        "O motivo da discrepância é que, em vez de calcular o RMSE sobre **todo o conjunto de validação**, calculamos o RMSE de **cada batch** e depois fizemos a média desses valores.  \n",
        "\n",
        "Essa abordagem **não é matematicamente equivalente** a calcular o RMSE considerando todas as amostras do conjunto de validação de uma só vez.\n",
        "\n",
        "Para resolver isso:\n",
        "\n",
        "- Podemos usar o **MSE como função de métrica** (`metric_fn`);\n",
        "- E definir a função de agregação (`aggregate_fn`) para calcular a **raiz quadrada da média dos MSEs**, obtendo assim o RMSE correto para todo o conjunto.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7DVK3iCMw3D",
        "outputId": "6ba90b3e-54cb-4710-acd6-dc6577b27a39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6388, device='cuda:0')"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model, valid_loader, mse,\n",
        "         aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwMtExdf9vCv"
      },
      "source": [
        "Para simplificar o cálculo de métricas e garantir precisão, podemos usar a biblioteca **TorchMetrics**, criada pela equipe do PyTorch Lightning. Ela oferece métricas de **streaming**, que permitem atualizar os resultados **batch a batch** sem perder o acompanhamento global da métrica.\n",
        "\n",
        "Principais vantagens:\n",
        "\n",
        "- Evita implementar métricas manualmente;\n",
        "- Mantém um registro contínuo das métricas ao longo de todo o conjunto de dados;\n",
        "- Funciona de forma eficiente em mini-batches.\n",
        "\n",
        "No Colab, a biblioteca não vem instalada por padrão, então é necessário executar:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22CgJlo3Mw3D"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "\n",
        "def evaluate_tm(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
        "    return metric.compute()  # compute the final result at the end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtPJNmjo-RzI"
      },
      "source": [
        "Com a TorchMetrics instalada, podemos:\n",
        "\n",
        "- Criar uma métrica de **RMSE em streaming**, que acompanha o desempenho ao longo de todos os batches;\n",
        "- **Mover a métrica para a GPU** para acelerar os cálculos;\n",
        "- Usá-la para **avaliar o conjunto de validação**, garantindo que o RMSE seja calculado de forma correta e eficiente para todo o dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP_RhMNzMw3D",
        "outputId": "0c2dffd0-7774-4eb6-9a30-4eadb79457e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6388, device='cuda:0')"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "evaluate_tm(model, valid_loader, rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK1RLX-LMw3D",
        "outputId": "f4eca81c-e5f7-49e8-db78-2ac7739c3c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, train loss: 0.7826, train metric: 0.8847, valid metric: 0.6690\n",
            "Epoch 2/20, train loss: 0.4362, train metric: 0.6605, valid metric: 0.6099\n",
            "Epoch 3/20, train loss: 0.3930, train metric: 0.6269, valid metric: 0.6145\n",
            "Epoch 4/20, train loss: 0.3759, train metric: 0.6132, valid metric: 0.5963\n",
            "Epoch 5/20, train loss: 0.3649, train metric: 0.6040, valid metric: 0.5911\n",
            "Epoch 6/20, train loss: 0.3598, train metric: 0.5999, valid metric: 0.5965\n",
            "Epoch 7/20, train loss: 0.3530, train metric: 0.5941, valid metric: 0.6061\n",
            "Epoch 8/20, train loss: 0.3495, train metric: 0.5911, valid metric: 0.6043\n",
            "Epoch 9/20, train loss: 0.3455, train metric: 0.5877, valid metric: 0.5723\n",
            "Epoch 10/20, train loss: 0.3416, train metric: 0.5846, valid metric: 0.6043\n",
            "Epoch 11/20, train loss: 0.3401, train metric: 0.5831, valid metric: 0.5882\n",
            "Epoch 12/20, train loss: 0.3362, train metric: 0.5799, valid metric: 0.5738\n",
            "Epoch 13/20, train loss: 0.3352, train metric: 0.5788, valid metric: 0.5873\n",
            "Epoch 14/20, train loss: 0.3310, train metric: 0.5754, valid metric: 0.5884\n",
            "Epoch 15/20, train loss: 0.3291, train metric: 0.5736, valid metric: 0.5608\n",
            "Epoch 16/20, train loss: 0.3272, train metric: 0.5721, valid metric: 0.5747\n",
            "Epoch 17/20, train loss: 0.3264, train metric: 0.5714, valid metric: 0.5839\n",
            "Epoch 18/20, train loss: 0.3238, train metric: 0.5691, valid metric: 0.5661\n",
            "Epoch 19/20, train loss: 0.3207, train metric: 0.5663, valid metric: 0.5556\n",
            "Epoch 20/20, train loss: 0.3190, train metric: 0.5649, valid metric: 0.5617\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def train2(model, optimizer, criterion, metric, train_loader, valid_loader,\n",
        "               n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            model.train()\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_tm(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50), nn.ReLU(),\n",
        "    nn.Linear(50, 40), nn.ReLU(),\n",
        "    nn.Linear(40, 30), nn.ReLU(),\n",
        "    nn.Linear(30, 1)\n",
        ")\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
        "                 n_epochs)\n",
        "\n",
        "# Since we compute the training metric\n",
        "plt.plot(np.arange(n_epochs) + 0.5, history[\"train_metrics\"], \".--\",\n",
        "         label=\"Training\")\n",
        "plt.plot(np.arange(n_epochs) + 1.0, history[\"valid_metrics\"], \".-\",\n",
        "         label=\"Validation\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.grid()\n",
        "plt.title(\"Learning curves\")\n",
        "plt.axis([0.5, 20, 0.4, 1.0])\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppT-e2rrBXsG"
      },
      "source": [
        "Agora que conseguimos calcular métricas corretamente, podemos atualizar a função `train()` para:\n",
        "\n",
        "- Avaliar o desempenho do modelo **durante o treinamento** no conjunto de treino a cada época;\n",
        "- Avaliar o desempenho no **conjunto de validação** ao final de cada época.\n",
        "\n",
        "### Observações importantes:\n",
        "\n",
        "- Se a performance no conjunto de treino for muito melhor que no conjunto de validação, isso pode indicar:\n",
        "  - **Overfitting**;\n",
        "  - Algum **erro nos dados**, como desajuste entre o conjunto de treino e validação.\n",
        "- É recomendável **plotar as curvas de aprendizado** para analisar essas diferenças, usando:\n",
        "  - **Matplotlib**;\n",
        "  - Ou ferramentas de visualização como **TensorBoard**.\n",
        "\n",
        "---\n",
        "\n",
        "## Próximos Passos\n",
        "\n",
        "Até agora, aprendemos a:\n",
        "\n",
        "- Construir, treinar e avaliar um **MLP de regressão** com PyTorch;\n",
        "- Utilizar o modelo treinado para fazer previsões.\n",
        "\n",
        "No entanto, tratamos apenas de **modelos sequenciais simples**, formados por camadas lineares e funções de ativação ReLU.  \n",
        "\n",
        "Para construir **modelos mais complexos e não sequenciais**, será necessário criar **módulos personalizados**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOo506bsMw3D"
      },
      "source": [
        "# 6. Building Nonsequential Models Using Custom Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJT-dGRMCSG7"
      },
      "source": [
        "Alguns modelos de redes neurais precisam receber **várias entradas** que não podem ser facilmente combinadas em um único tensor. Isso ocorre, por exemplo, quando as entradas possuem **diferentes números de dimensões**, como no caso de se alimentar a rede neural com **imagens e textos** ao mesmo tempo.  \n",
        "\n",
        "Para lidar com essas situações, precisamos **adaptar o método `forward()`** do modelo para aceitar e processar múltiplas entradas separadamente.  \n",
        "\n",
        "No caso do modelo **Wide & Deep**, que combina diferentes tipos de dados (wide features e deep features), essa adaptação permite que cada entrada seja processada adequadamente antes de serem combinadas na rede.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\" style=\"margin-top:20px; margin-bottom:20px;\">\n",
        "  \n",
        "![wide_deep](Aula_Imagens\\wide_deep.png)\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1xgvOF-Mw3D"
      },
      "outputs": [],
      "source": [
        "class WideAndDeep(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + n_features, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        deep_output = self.deep_stack(X)\n",
        "        wide_and_deep = torch.concat([X, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmwTklXvLRVl"
      },
      "source": [
        "No PyTorch, podemos incorporar **qualquer tipo de módulo** dentro de um módulo personalizado. No caso do modelo **Wide & Deep**:\n",
        "\n",
        "- A parte \"deep\" é construída com **`nn.Sequential`**, implementando uma MLP (mesma arquitetura usada anteriormente, mas em um exemplo simplificado).\n",
        "- A **camada de saída** foi separada, pois precisa receber a **concatenação da entrada do modelo com a saída da parte deep**.\n",
        "- Consequentemente, a camada de saída agora possui **`40 + n_features`** entradas, ao invés de apenas 40.\n",
        "\n",
        "No método `forward()`:\n",
        "\n",
        "1. Passamos a entrada `X` para a **stack deep**.\n",
        "2. Concatenamos **`X` com a saída da stack deep**.\n",
        "3. Alimentamos a **camada de saída** com essa concatenação.\n",
        "\n",
        "Após a definição do modelo, podemos:\n",
        "\n",
        "- **Criar uma instância** do módulo personalizado.\n",
        "- **Mover para GPU** para acelerar o treinamento.\n",
        "- **Treinar, avaliar e usar** o modelo da mesma forma que os modelos anteriores.\n",
        "\n",
        "Essa abordagem permite lidar com **entradas múltiplas** e combinações de módulos de forma flexível, mantendo a simplicidade no pipeline de treinamento e inferência.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pko67YJ2Mw3D"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = WideAndDeep(n_features).to(device)\n",
        "learning_rate = 0.002  # the model changed, so did the optimal learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFuWFRDTMw3D",
        "outputId": "847fdf66-af0b-4378-bbdf-7eb8c9601115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, train loss: 1.7802, train metric: 1.3344, valid metric: 0.8690\n",
            "Epoch 2/20, train loss: 0.6201, train metric: 0.7875, valid metric: 0.9492\n",
            "Epoch 3/20, train loss: 0.5900, train metric: 0.7682, valid metric: 0.7331\n",
            "Epoch 4/20, train loss: 0.5607, train metric: 0.7488, valid metric: 0.7771\n",
            "Epoch 5/20, train loss: 0.5408, train metric: 0.7353, valid metric: 0.7967\n",
            "Epoch 6/20, train loss: 0.5244, train metric: 0.7241, valid metric: 0.7098\n",
            "Epoch 7/20, train loss: 0.5070, train metric: 0.7119, valid metric: 0.7419\n",
            "Epoch 8/20, train loss: 0.4941, train metric: 0.7030, valid metric: 0.6750\n",
            "Epoch 9/20, train loss: 0.4798, train metric: 0.6928, valid metric: 0.6762\n",
            "Epoch 10/20, train loss: 0.4657, train metric: 0.6825, valid metric: 0.6678\n",
            "Epoch 11/20, train loss: 0.4538, train metric: 0.6736, valid metric: 0.6617\n",
            "Epoch 12/20, train loss: 0.4441, train metric: 0.6665, valid metric: 0.6651\n",
            "Epoch 13/20, train loss: 0.4328, train metric: 0.6580, valid metric: 0.6803\n",
            "Epoch 14/20, train loss: 0.4232, train metric: 0.6506, valid metric: 0.6288\n",
            "Epoch 15/20, train loss: 0.4139, train metric: 0.6434, valid metric: 0.6202\n",
            "Epoch 16/20, train loss: 0.4063, train metric: 0.6374, valid metric: 0.6216\n",
            "Epoch 17/20, train loss: 0.3991, train metric: 0.6317, valid metric: 0.6129\n",
            "Epoch 18/20, train loss: 0.3937, train metric: 0.6274, valid metric: 0.6031\n",
            "Epoch 19/20, train loss: 0.3879, train metric: 0.6228, valid metric: 0.6092\n",
            "Epoch 20/20, train loss: 0.3834, train metric: 0.6193, valid metric: 0.5957\n"
          ]
        }
      ],
      "source": [
        "# extra code: train the model, exactly our previous models\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
        "                 n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oraxe21Lah3"
      },
      "source": [
        "Em alguns casos, pode ser necessário enviar **subconjuntos diferentes de features** por caminhos distintos do modelo, como:\n",
        "\n",
        "- Algumas features passam pelo **caminho wide**.\n",
        "- Outras features (possivelmente sobrepostas) passam pelo **caminho deep**.\n",
        "\n",
        "Para isso, uma abordagem comum é **dividir as entradas dentro do método `forward()`**.  \n",
        "\n",
        "Isso permite controlar exatamente quais features alimentam cada parte da rede, garantindo maior flexibilidade no processamento dos dados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN4qtgAeMw3E"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepV2(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + 5, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_wide = X[:, :5]\n",
        "        X_deep = X[:, 2:]\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uW-6d5TLwWM"
      },
      "source": [
        "Embora seja possível dividir os inputs dentro do método `forward()`, muitas vezes é **mais conveniente que o modelo aceite dois tensores separados** como entrada.  \n",
        "\n",
        "Vantagens dessa abordagem:\n",
        "\n",
        "- **Mais claro e organizado**: cada tensor representa explicitamente um subconjunto de features.\n",
        "- **Evita confusões** ao separar manualmente os dados dentro do forward.\n",
        "- **Facilita a reutilização** do modelo em diferentes contextos, como combinar imagens e textos ou diferentes tipos de dados estruturados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUnuam2-Mw3E"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = WideAndDeepV2(n_features).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s4nF41HMw3E",
        "outputId": "2161426c-02a6-4d7d-8061-3ece239f16d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, train loss: 1.8482, train metric: 1.3598, valid metric: 0.9100\n",
            "Epoch 2/20, train loss: 0.6282, train metric: 0.7927, valid metric: 0.8028\n",
            "Epoch 3/20, train loss: 0.5763, train metric: 0.7591, valid metric: 0.7567\n",
            "Epoch 4/20, train loss: 0.5413, train metric: 0.7356, valid metric: 0.7290\n",
            "Epoch 5/20, train loss: 0.5099, train metric: 0.7142, valid metric: 0.7011\n",
            "Epoch 6/20, train loss: 0.4841, train metric: 0.6958, valid metric: 0.6816\n",
            "Epoch 7/20, train loss: 0.4656, train metric: 0.6824, valid metric: 0.6670\n",
            "Epoch 8/20, train loss: 0.4526, train metric: 0.6728, valid metric: 0.6576\n",
            "Epoch 9/20, train loss: 0.4438, train metric: 0.6662, valid metric: 0.6539\n",
            "Epoch 10/20, train loss: 0.4380, train metric: 0.6618, valid metric: 0.6498\n",
            "Epoch 11/20, train loss: 0.4326, train metric: 0.6577, valid metric: 0.6470\n",
            "Epoch 12/20, train loss: 0.4284, train metric: 0.6546, valid metric: 0.6447\n",
            "Epoch 13/20, train loss: 0.4253, train metric: 0.6521, valid metric: 0.6452\n",
            "Epoch 14/20, train loss: 0.4216, train metric: 0.6494, valid metric: 0.6468\n",
            "Epoch 15/20, train loss: 0.4190, train metric: 0.6473, valid metric: 0.6484\n",
            "Epoch 16/20, train loss: 0.4169, train metric: 0.6458, valid metric: 0.6452\n",
            "Epoch 17/20, train loss: 0.4144, train metric: 0.6438, valid metric: 0.6459\n",
            "Epoch 18/20, train loss: 0.4118, train metric: 0.6417, valid metric: 0.6470\n",
            "Epoch 19/20, train loss: 0.4101, train metric: 0.6404, valid metric: 0.6475\n",
            "Epoch 20/20, train loss: 0.4082, train metric: 0.6389, valid metric: 0.6493\n"
          ]
        }
      ],
      "source": [
        "# extra code: train the model, exactly our previous models\n",
        "learning_rate = 0.002\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
        "                 n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8whgJQhFMw3E"
      },
      "source": [
        "## 6.1 Building Models with Multiple Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BslPo-MAL74z"
      },
      "source": [
        "Alguns modelos de redes neurais precisam receber **mais de uma entrada** que não podem ser facilmente combinadas em um único tensor. Isso acontece, por exemplo, quando as entradas possuem **diferentes números de dimensões**, como ao alimentar a rede com **imagens e textos simultaneamente**.\n",
        "\n",
        "Para que o modelo **Wide & Deep** aceite **duas entradas separadas** (como ilustrado na Figura 10-2 do livro), é necessário **adaptar o método `forward()`** do modelo para processar cada entrada individualmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7lv_HTBMw3E"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepV3(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + 5, 1)\n",
        "\n",
        "    def forward(self, X_wide, X_deep):\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\" style=\"margin-top:20px; margin-bottom:20px;\">\n",
        "  \n",
        "![concat](Aula_Imagens\\concat.png)\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxf7X25AMQPu"
      },
      "source": [
        "Para trabalhar com múltiplas entradas no modelo Wide & Deep, precisamos criar **datasets que retornem separadamente as entradas para o caminho wide e para o caminho deep**.\n",
        "\n",
        "Isso garante que cada subconjunto de features seja fornecido ao caminho correto da rede, mantendo a consistência e a clareza do fluxo de dados durante o treinamento e a avaliação.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obd9jF07Mw3E"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "train_data_wd = TensorDataset(X_train[:, :5], X_train[:, 2:], y_train)\n",
        "train_loader_wd = DataLoader(train_data_wd, batch_size=32, shuffle=True)\n",
        "valid_data_wd = TensorDataset(X_valid[:, :5], X_valid[:, 2:], y_valid)\n",
        "valid_loader_wd = DataLoader(valid_data_wd, batch_size=32)\n",
        "test_data_wd = TensorDataset(X_test[:, :5], X_test[:, 2:], y_test)\n",
        "test_loader_wd = DataLoader(test_data_wd, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8urBGzhpMw3E",
        "outputId": "d6535768-ef7f-4453-9e60-1e775e2dcb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
            "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
            "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
            "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
            "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
            "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
            "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
            "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
            "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
            "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
            "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
            "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
            "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
            "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
            "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
            "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
            "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
            "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
            "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
            "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
          ]
        }
      ],
      "source": [
        "def evaluate_multi_in(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for X_batch_wide, X_batch_deep, y_batch in data_loader:\n",
        "            X_batch_wide = X_batch_wide.to(device)\n",
        "            X_batch_deep = X_batch_deep.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(X_batch_wide, X_batch_deep)\n",
        "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
        "    return metric.compute()  # compute the final result at the end\n",
        "\n",
        "def train_multi_in(model, optimizer, criterion, metric, train_loader,\n",
        "                   valid_loader, n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for *X_batch_inputs, y_batch in train_loader:\n",
        "            model.train()\n",
        "            X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(*X_batch_inputs)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_multi_in(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = WideAndDeepV3(n_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train_multi_in(model, optimizer, mse, rmse, train_loader_wd,\n",
        "                         valid_loader_wd, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGDCAjXuMaUu"
      },
      "source": [
        "Quando o modelo possui **múltiplas entradas**, é fácil confundir a ordem dos tensores, o que pode gerar **erros difíceis de depurar**.\n",
        "\n",
        "Para evitar isso, uma boa prática é **nomear cada entrada**.  \n",
        "\n",
        "Uma abordagem é criar um **dataset personalizado** que retorne um **dicionário**, onde as chaves são os nomes das entradas e os valores são os tensores correspondentes.  \n",
        "\n",
        "Isso torna o código mais legível e reduz a chance de erros ao alimentar o modelo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkkt0E7KMw3E"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_wide, X_deep, y):\n",
        "        self.X_wide = X_wide\n",
        "        self.X_deep = X_deep\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_dict = {\"X_wide\": self.X_wide[idx], \"X_deep\": self.X_deep[idx]}\n",
        "        return input_dict, self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8_Ex2oMhyk"
      },
      "source": [
        "Após definir como as entradas serão retornadas (separadas ou nomeadas), o próximo passo é **criar os datasets e os data loaders**.\n",
        "\n",
        "- **Datasets**: fornecem os dados ao modelo de forma estruturada, retornando os tensores correspondentes a cada entrada.\n",
        "- **Data Loaders**: permitem iterar sobre os datasets em **mini-batches**, embaralhar os dados e facilitar o treinamento eficiente no PyTorch.\n",
        "\n",
        "Essa etapa garante que o modelo receba os dados corretamente e de forma eficiente durante o treinamento e avaliação.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WuTt7s8Mw3E"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "train_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_train[:, :5], X_deep=X_train[:, 2:], y=y_train)\n",
        "train_loader_named = DataLoader(train_data_named, batch_size=32, shuffle=True)\n",
        "valid_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_valid[:, :5], X_deep=X_valid[:, 2:], y=y_valid)\n",
        "valid_loader_named = DataLoader(valid_data_named, batch_size=32)\n",
        "test_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_test[:, :5], X_deep=X_test[:, 2:], y=y_test)\n",
        "test_loader_named = DataLoader(test_data_named, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gXnzV15Mw3F",
        "outputId": "f5ca1d77-8ada-43de-8c68-a2a4d7ade86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
            "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
            "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
            "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
            "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
            "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
            "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
            "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
            "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
            "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
            "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
            "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
            "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
            "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
            "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
            "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
            "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
            "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
            "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
            "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
          ]
        }
      ],
      "source": [
        "def evaluate_named(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for inputs, y_batch in data_loader:\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(X_wide=inputs[\"X_wide\"], X_deep=inputs[\"X_deep\"])\n",
        "            metric.update(y_pred, y_batch)\n",
        "    return metric.compute()  # compute the final result at the end\n",
        "\n",
        "def train_named(model, optimizer, criterion, metric, train_loader,\n",
        "                   valid_loader, n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for inputs, y_batch in train_loader:\n",
        "            model.train()\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(**inputs)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_named(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = WideAndDeepV3(n_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train_named(model, optimizer, mse, rmse, train_loader_named,\n",
        "                      valid_loader_named, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdaO98xVMw3F"
      },
      "source": [
        "## 6.2 Building Models with Multiple Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WyUNPYGNZx7"
      },
      "source": [
        "\n",
        "Existem diversos cenários em que **uma rede neural precisa ter múltiplas saídas**:\n",
        "\n",
        "### 1. Tarefas que exigem múltiplos tipos de previsão\n",
        "- Por exemplo, localizar e classificar o objeto principal em uma imagem.\n",
        "- Isso combina **regressão** (localização) e **classificação** (tipo do objeto) na mesma rede.\n",
        "\n",
        "### 2. Multitask Learning (Aprendizado Multitarefa)\n",
        "- Quando temos **múltimas tarefas independentes** com base nos mesmos dados.\n",
        "- Treinar uma rede por tarefa é possível, mas **treinar uma única rede com uma saída por tarefa** geralmente gera melhores resultados.\n",
        "- A rede aprende **features compartilhadas úteis** para todas as tarefas.\n",
        "- Exemplo: classificar expressões faciais (sorriso, surpresa) e identificar se a pessoa usa óculos simultaneamente.\n",
        "\n",
        "### 3. Regularização com Saídas Auxiliares\n",
        "- Adicionar uma saída auxiliar ajuda a **reduzir overfitting** e melhorar a generalização.\n",
        "- A saída auxiliar força a **parte subjacente da rede** a aprender algo útil por si só.\n",
        "- Exemplo no modelo **Wide & Deep**:\n",
        "  - A saída da stack deep tem dimensão 40.\n",
        "  - O alvo tem dimensão 1.\n",
        "  - Adicionamos uma camada **`nn.Linear`** para mapear de 40 → 1 para a saída auxiliar.\n",
        "  - O método `forward()` deve calcular **tanto a saída principal quanto a saída auxiliar**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\" style=\"margin-top:20px; margin-bottom:20px;\">\n",
        "  \n",
        "![concat](Aula_Imagens\\aux_out.png)\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhd4d4HtMw3F"
      },
      "outputs": [],
      "source": [
        "class WideAndDeepV4(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 40), nn.ReLU(),\n",
        "            nn.Linear(40, 30), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(30 + 5, 1)\n",
        "        self.aux_output_layer = nn.Linear(30, 1)\n",
        "\n",
        "    def forward(self, X_wide, X_deep):\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        main_output = self.output_layer(wide_and_deep)\n",
        "        aux_output = self.aux_output_layer(deep_output)\n",
        "        return main_output, aux_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdyhKzwhMw3F",
        "outputId": "2f4e7029-a84f-40b3-ab3d-67e45252af9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, train loss: 1.0693, train metric: 0.9506, valid metric: 0.7085\n",
            "Epoch 2/20, train loss: 0.5817, train metric: 0.6946, valid metric: 0.6607\n",
            "Epoch 3/20, train loss: 0.5010, train metric: 0.6581, valid metric: 0.6425\n",
            "Epoch 4/20, train loss: 0.4690, train metric: 0.6497, valid metric: 0.6654\n",
            "Epoch 5/20, train loss: 0.4503, train metric: 0.6420, valid metric: 0.6338\n",
            "Epoch 6/20, train loss: 0.4387, train metric: 0.6373, valid metric: 0.6563\n",
            "Epoch 7/20, train loss: 0.4315, train metric: 0.6330, valid metric: 0.6193\n",
            "Epoch 8/20, train loss: 0.4249, train metric: 0.6302, valid metric: 0.6167\n",
            "Epoch 9/20, train loss: 0.4116, train metric: 0.6202, valid metric: 0.6450\n",
            "Epoch 10/20, train loss: 0.4085, train metric: 0.6198, valid metric: 0.5938\n",
            "Epoch 11/20, train loss: 0.4073, train metric: 0.6197, valid metric: 0.5959\n",
            "Epoch 12/20, train loss: 0.3914, train metric: 0.6078, valid metric: 0.6073\n",
            "Epoch 13/20, train loss: 0.3847, train metric: 0.6033, valid metric: 0.5815\n",
            "Epoch 14/20, train loss: 0.3849, train metric: 0.6048, valid metric: 0.6042\n",
            "Epoch 15/20, train loss: 0.3744, train metric: 0.5965, valid metric: 0.5740\n",
            "Epoch 16/20, train loss: 0.3690, train metric: 0.5928, valid metric: 0.6111\n",
            "Epoch 17/20, train loss: 0.3675, train metric: 0.5923, valid metric: 0.5766\n",
            "Epoch 18/20, train loss: 0.3606, train metric: 0.5869, valid metric: 0.5782\n",
            "Epoch 19/20, train loss: 0.3604, train metric: 0.5867, valid metric: 0.5664\n",
            "Epoch 20/20, train loss: 0.3566, train metric: 0.5837, valid metric: 0.5654\n"
          ]
        }
      ],
      "source": [
        "import torchmetrics\n",
        "\n",
        "def evaluate_multi_out(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for inputs, y_batch in data_loader:\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred, _ = model(**inputs)\n",
        "            metric.update(y_pred, y_batch)\n",
        "    return metric.compute()\n",
        "\n",
        "def train_multi_out(model, optimizer, criterion, metric, train_loader,\n",
        "                   valid_loader, n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for inputs, y_batch in train_loader:\n",
        "            model.train()\n",
        "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred, y_pred_aux = model(**inputs)\n",
        "            main_loss = criterion(y_pred, y_batch)\n",
        "            aux_loss = criterion(y_pred_aux, y_batch)\n",
        "            loss = 0.8 * main_loss + 0.2 * aux_loss\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_multi_out(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history\n",
        "\n",
        "torch.manual_seed(42)\n",
        "learning_rate = 0.01\n",
        "model = WideAndDeepV4(n_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
        "mse = nn.MSELoss()\n",
        "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "history = train_multi_out(model, optimizer, mse, rmse, train_loader_named,\n",
        "                          valid_loader_named, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRjkXy2RMw3F"
      },
      "source": [
        "# 7. Building an Image Classifier with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwisMObnOAJe"
      },
      "source": [
        "Neste capítulo, continuaremos trabalhando com o **dataset Fashion MNIST**. A primeira etapa é fazer o download dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPKxBYnOMw3F"
      },
      "source": [
        "## 7.1 Using TorchVision to Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8MvBcAnO0Q3"
      },
      "source": [
        "A **TorchVision** é uma biblioteca essencial no ecossistema PyTorch para **visão computacional**. Ela oferece:\n",
        "\n",
        "- Funções utilitárias para **baixar datasets comuns**, como MNIST e Fashion MNIST.  \n",
        "- **Modelos pré-treinados** para diversas tarefas de visão computacional (ver Capítulo 12).  \n",
        "- Funções para **transformar imagens**, incluindo corte, rotação, redimensionamento, entre outras.  \n",
        "\n",
        "> Observação: No Google Colab, a TorchVision já vem pré-instalada.\n",
        "\n",
        "No caso do Fashion MNIST:\n",
        "\n",
        "- O dataset já vem dividido em:\n",
        "  - **Treinamento:** 60.000 imagens  \n",
        "  - **Teste:** 10.000 imagens  \n",
        "- Para validação, podemos reservar **5.000 imagens** do conjunto de treinamento usando a função `random_split()` do PyTorch.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrCdqjYPMw3F",
        "outputId": "8075d05d-cdf5-43eb-90d8-f0330b78797a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 178kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.26MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
        "\n",
        "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=True, download=True, transform=toTensor)\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=False, download=True, transform=toTensor)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_data, valid_data = torch.utils.data.random_split(\n",
        "    train_and_valid_data, [55_000, 5_000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbwvaWVcMw3F"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0FnGjPgMw3F"
      },
      "source": [
        "Each entry is a tuple (image, target):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxRQ3KcHMw3G"
      },
      "outputs": [],
      "source": [
        "X_sample, y_sample = train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-_iW25LOqCE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KF41mm8Mw3G"
      },
      "source": [
        "Each image has a shape \\[channels, rows, columns\\]. Grayscale images like in Fashion MNIST have a single channel (while RGB images have 3, and other types of images, such as satellite images, may have many more). Fashion images are grayscale and 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDv59Z5EMw3G",
        "outputId": "0821ae7e-bbe4-40ce-a67d-55fcd4b6f89e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbSgYYXuMw3G",
        "outputId": "851c8f57-d60a-4982-a857-6d01fde14f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_sample.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyxM4YY0Mw3G",
        "outputId": "e865f83b-29b8-4da6-e1f5-cacc84c18a42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ankle boot'"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_and_valid_data.classes[y_sample]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dImjG69aMw3L"
      },
      "source": [
        "![NCIA2](NCIA_Images\\end.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
